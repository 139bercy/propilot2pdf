{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comment fonctionne la transposition de texte ?\n",
    "\n",
    "1. Générer les fiches avec les nouvelles valeurs via build_report dans un dossier **template_dir**\n",
    "2. Télécharger toutes les fiches d'Osmose dans un dossier **modified_docx_dir** (créer ce dossier soi-même)\n",
    "3. Lancer ce notebook pour une transposition **modified_docx_dir** -> **transposed_docx_dir** en réutilisant les nouvelles fiches-templates générées dans **template_dir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "# Permet la génération de word\n",
    "import docx\n",
    "from docx import Document\n",
    "from docxcompose.composer import Composer\n",
    "from docxtpl import DocxTemplate, R, Listing, InlineImage\n",
    "from docx.shared import Mm\n",
    "\n",
    "# Parsing des commentaires\n",
    "from docx2python import docx2python\n",
    "\n",
    "# Nettoyage du texte\n",
    "import html\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_dir = \"./reports_word\"\n",
    "modified_docx_dir = \"./modified_reports\"\n",
    "transposed_docx_dir = \"./reports_word/transposed_reports\"\n",
    "image_folder = \"./reports_word/reports_images\"\n",
    "\n",
    "\n",
    "def mkdir_ifnotexist(path) :\n",
    "    if not os.path.isdir(path) :\n",
    "        os.mkdir(path)\n",
    "        \n",
    "        \n",
    "mkdir_ifnotexist(transposed_docx_dir)\n",
    "mkdir_ifnotexist(image_folder)\n",
    "assert os.path.exists(modified_docx_dir), f\"Le dossier {modified_docx_dir} n'existe pas. Vous devez le créer et y placer les docx contenant les commentaires à déplacer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_name(name):\n",
    "    # Normalise le nom de la mesure ou volet, notamment pour l'utiliser comme nom de code dans les commentaires\n",
    "    name = name.lower()\n",
    "    name = unidecode(name)\n",
    "    name = re.sub('[^a-z]', ' ',  name)\n",
    "    name = re.sub(' +', '', name)\n",
    "    return name\n",
    "\n",
    "\n",
    "# Les mesures des fiches v1\n",
    "volet2mesures = {\n",
    "'Ecologie': [\"Ma Prime Rénov'\",\n",
    "\t\t\"Bonus électrique\",\n",
    "\t\t'AAP Efficacité énergétique',\n",
    "        \"AAP industrie : Modernisation des filières auto et aéro\",\n",
    "\t\t'Prime à la conversion des véhicules légers',\n",
    "\t\t'Soutien recherche aéronautique civil', \n",
    "\t\t'Rénovation des bâtiments Etats (marchés notifiés)',],\n",
    "\n",
    "'Compétitivité': ['Assurance prospection', \n",
    "\t\t'France Num : aide à la numérisation des TPE,PME,ETI',\n",
    "\t\t\"AAP Industrie : Soutien aux projets industriels territoires\",\n",
    "\t\t\"AAP Industrie : Sécurisation approvisionnements critiques\",\n",
    "\t\t\"Renforcement subventions Business France\",],\n",
    "\n",
    "'Cohésion': [\"Apprentissage\",\n",
    "\t\t\"Prime à l'embauche des jeunes\",\n",
    "\t\t\"Prime à l'embauche pour les travailleurs handicapés\",\n",
    "\t\t\"Contrats Initiatives Emploi (CIE) Jeunes\",\n",
    "\t\t'Contrats de professionnalisation',\n",
    "\t\t'Garantie jeunes',\n",
    "\t\t\"Parcours emploi compétences (PEC) Jeunes\",\n",
    "\t\t\"Service civique\",]\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_prefixes = set(['Espace Commentaires\\xa0:', 'Espace Commentaires :', \n",
    "                        'Exemples de lauréats :', 'Exemples de lauréats\\xa0:', \n",
    "                       \"Commentaires généraux\\xa0:\", \"Commentaires généraux :\", \n",
    "                       \"Volet\\xa0: Ecologie\", \"Volet\\xa0: Compétitivité\", \"Volet\\xa0: Cohésion\",\n",
    "                       \"Volet : Ecologie\", \"Volet : Compétitivité\", \"Volet : Cohésion\",])\n",
    "\n",
    "def flatten(L):\n",
    "    # Aplatir une liste imbriquée [[., ., [[.]]]] -> [., ., .]\n",
    "    if type(L) is list:\n",
    "        for item in L:\n",
    "            yield from flatten(item)\n",
    "    else:\n",
    "        yield L\n",
    "        \n",
    "\n",
    "def gen_unit_list(L):\n",
    "    if (type(L) is list) and (len(L) > 0) and (type(L[0]) is not list):\n",
    "        yield L\n",
    "    else:\n",
    "        for item in L:\n",
    "            yield from gen_unit_list(item)\n",
    "\n",
    "\n",
    "def count_occurence(texts):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter[text] += 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "def reformat_bullet_point(text):\n",
    "    return re.sub('^--\\t', '- ', text)\n",
    "\n",
    "\n",
    "def reformat_url(text):\n",
    "    regex_clean = re.compile('<a href.*?>')\n",
    "    text = re.sub(regex_clean, '', text)\n",
    "    text = re.sub('</a>', \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_comment(textbox_content):\n",
    "    occurences = count_occurence(textbox_content)\n",
    "    text_to_keep = []\n",
    "    flag_text = None\n",
    "    for text in textbox_content:\n",
    "        if occurences[text] == 2 and flag_text == text:\n",
    "            # On rencontre le début du commentaire pour la deuxième fois.\n",
    "            break\n",
    "        elif occurences[text] == 2 and flag_text == None and not text.isdigit():\n",
    "            # On renconre le début du commentaire pour la première fois\n",
    "            flag_text = text\n",
    "        text_to_keep.append(text)\n",
    "\n",
    "    textbox_content = text_to_keep\n",
    "    \n",
    "    # Cleaning section\n",
    "    texts = []\n",
    "    for text in textbox_content:\n",
    "        text = html.unescape(text)\n",
    "        text = reformat_bullet_point(text)\n",
    "        text = reformat_url(text)\n",
    "        \n",
    "        texts.append(text)\n",
    "    textbox_content = texts\n",
    "    ###\n",
    "\n",
    "    textbox_content = [text.strip() for text in textbox_content]\n",
    "    textbox_content = '\\n'.join(textbox_content)\n",
    "    textbox_content = textbox_content.strip()\n",
    "\n",
    "    # Retirer un potentiel préfix (Espace Commentaires ...)\n",
    "    textbox_content = re.sub('^[0-9]+[\\r\\n]+[0-9]+', '', textbox_content).strip()\n",
    "    prefix_clean = False\n",
    "    while not prefix_clean:\n",
    "        # Les préfixes étant déclarés dans un set, dès lors qu'on retrouve un préfixe à retirer,\n",
    "        # on re-parcourt le set de préfixes \n",
    "        prefix_clean = True\n",
    "        for prefix in comment_prefixes:\n",
    "            if textbox_content.startswith(prefix):\n",
    "                textbox_content = textbox_content.replace(prefix, \"\", 1)\n",
    "                textbox_content = textbox_content.strip()\n",
    "                prefix_clean = False\n",
    "            if textbox_content.endswith(prefix):\n",
    "                textbox_content = textbox_content[:-len(prefix)]\n",
    "                textbox_content = textbox_content.strip()\n",
    "                prefix_clean = False\n",
    "            \n",
    "    \n",
    "    textbox_content = textbox_content.strip()\n",
    "    # Carriage pour conserver les retours à la ligne\n",
    "    textbox_content = re.sub(\"\\n\", \"\\r\\n\", textbox_content)\n",
    "    # Changer tous les \"plan de relance\" en \"plan France Relance\" ------------------------------------ !!!!!!!!!!!!!!!!!!!!\n",
    "    textbox_content = re.sub(\"plan de relance\", \"plan France Relance\", textbox_content)\n",
    "    return textbox_content\n",
    "    \n",
    "\n",
    "def alternate_texts_and_images(doc, textbox_content):\n",
    "    r = re.compile(\"----media/(.*?)----\")\n",
    "    image_names = r.findall(textbox_content) + [None]\n",
    "    texts = r.split(textbox_content)\n",
    "    \n",
    "    frameworks = []\n",
    "    for text, image_basename in zip(texts[0::2], image_names):\n",
    "        if image_basename is not None:\n",
    "            image_path = os.path.join(image_folder, image_basename)\n",
    "            frameworks.append({'text': text, 'image': InlineImage(doc, image_path, height=Mm(40))})\n",
    "        else:\n",
    "            frameworks.append({'text': text, 'image': ''})\n",
    "        \n",
    "        if text.strip().isdigit():\n",
    "            print('---- Récupération ratée ! Probablement un numéro de page attrapé au lieu du texte')\n",
    "    return frameworks\n",
    "\n",
    "\n",
    "def get_volet_to_comment(doc, content, volets2mesures):\n",
    "    volet2comment = {}\n",
    "    body = content.body\n",
    "    count_mesures = 0\n",
    "    for text_list in gen_unit_list(content.body):                \n",
    "        volet = None\n",
    "        for text in text_list:\n",
    "            clean_text = text.lower().strip()\n",
    "            clean_text = re.sub('\\xa0', ' ', clean_text)\n",
    "            if clean_text.startswith('volet :'):\n",
    "                volet = clean_text.split(':')[-1].strip()\n",
    "                \n",
    "        if volet is not None:\n",
    "            # Filtrer des retours à la lignes\n",
    "            textbox_content = text_list\n",
    "            textbox_content = textbox_content[:-7]\n",
    "\n",
    "            # On extrait le commentaire\n",
    "            textbox_content = extract_comment(textbox_content)\n",
    "            frameworks = alternate_texts_and_images(doc, textbox_content)\n",
    "\n",
    "            # On associe volet et commentaire\n",
    "            encoded_volet = encode_name(volet)\n",
    "            volet2comment[encoded_volet] = frameworks\n",
    "    return volet2comment\n",
    "\n",
    "\n",
    "def get_mesure_to_comment(doc, content, volet2mesures):\n",
    "    mesure2comment = {}\n",
    "    body = content.body\n",
    "    # Les mesures doivent apparaitre dans le même ordre que le document\n",
    "    ordered_mesures = [mesure for mesures in volet2mesures.values() for mesure in mesures]\n",
    "\n",
    "    for i in range(1, len(ordered_mesures)+1):\n",
    "        # On extrait la partie textuelle à copier\n",
    "        textbox_content = body[2 + 6 * i][0][0]\n",
    "\n",
    "        # Filtrer des retours à la lignes et potentiels num page\n",
    "        while len(textbox_content) > 0 and (textbox_content[0] == '' or textbox_content[0].strip().isdigit()):\n",
    "            textbox_content = textbox_content[1:]\n",
    "                \n",
    "        # On extrait le commentaire\n",
    "        textbox_content = extract_comment(textbox_content)\n",
    "        frameworks = alternate_texts_and_images(doc, textbox_content)\n",
    "        \n",
    "        # On associe la mesure au commentaire\n",
    "        encoded_mesure = encode_name(ordered_mesures[i-1])\n",
    "        mesure2comment[encoded_mesure] = frameworks  #textbox_content\n",
    "    assert len(mesure2comment) == len(ordered_mesures)\n",
    "    \n",
    "    # Utiliser les nouvelles mesures : v1->v2\n",
    "    if False:\n",
    "        new_mesure2comment = {}\n",
    "        for encoded_old_mesure, comment in mesure2comment.items():\n",
    "            if encoded_old_mesure in encoded_old2encoded_new_mesure:\n",
    "                # On change la clé du dict par la nouvelle mesure\n",
    "                encoded_new_mesure = encoded_old2encoded_new_mesure[encoded_old_mesure]\n",
    "                new_mesure2comment[encoded_new_mesure] = comment\n",
    "            else:\n",
    "                # On réutilise la même clé / pas de changement causé par un renommage\n",
    "                new_mesure2comment[encoded_old_mesure] = comment\n",
    "\n",
    "        assert len(new_mesure2comment) == len(mesure2comment)\n",
    "    \n",
    "    return mesure2comment\n",
    "\n",
    "\n",
    "#src_filename = \"/home/yves/code/propilot2pdf/modified_reports/Suivi Territorial plan relance Loiret.docx\"\n",
    "#template_filename = \"reports_word/Suivi_Territorial_plan_relance_Charente.docx\"\n",
    "\n",
    "#content = docx2python(src_filename)\n",
    "#doc = DocxTemplate(template_filename)\n",
    "\n",
    "#volet2comment = get_volet_to_comment(doc, content, volet2mesures)\n",
    "#volet2comment\n",
    "\n",
    "#mesure2comment = get_mesure_to_comment(doc, content, volet2mesures)\n",
    "#mesure2comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_comments(src_filename, template_filename, output_filename, volet2mesures):\n",
    "    # Lecture du document\n",
    "    content = docx2python(src_filename, image_folder=image_folder)\n",
    "    doc_template = DocxTemplate(template_filename)\n",
    "    \n",
    "    # Parse les commentaires sous les volets et mesures\n",
    "    mesure2comment = get_mesure_to_comment(doc_template, content, volet2mesures)\n",
    "    volet2comment = get_volet_to_comment(doc_template, content, volet2mesures)\n",
    "    context = {**mesure2comment, **volet2comment}\n",
    "\n",
    "    # On génère un nouveau document avec les commentaires recopiés\n",
    "    doc_template.render(context, autoescape=True)\n",
    "    doc_template.save(output_filename)\n",
    "    return output_filename\n",
    "\n",
    "\n",
    "#template_filename = '/home/yves/code/propilot2pdf/reports_word/Suivi_Territorial_plan_relance_Ain.docx'\n",
    "#src_filename = \"/home/yves/Bureau/FP/fiches_modifiees/Suivi Territorial plan relance Puy-de-Dôme 6 mai 2021.docx\"\n",
    "#output_filename = \"out.docx\"\n",
    "\n",
    "#transpose_comments(src_filename, template_filename, output_filename, volet2mesures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_template(template_filename, output_filename, volet2mesures):\n",
    "    ordered_mesures = [mesure for mesures in volet2mesures.values() for mesure in mesures]\n",
    "    ordered_volets = list(volet2mesures.keys())\n",
    "    \n",
    "    context = {encode_name(volet): [{'text': '', 'image': ''}] for volet in ordered_volets}\n",
    "    \n",
    "    doc = DocxTemplate(template_filename)\n",
    "    doc.render(context, autoescape=True)\n",
    "    doc.save(output_filename)\n",
    "    return output_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [os.path.join(template_dir, filename) for filename in os.listdir(template_dir) if filename.endswith('docx')]\n",
    "modified_docx = [os.path.join(modified_docx_dir, filename) for filename in os.listdir(modified_docx_dir) if filename.endswith('docx')]\n",
    "\n",
    "def map_templates_to_modified_reports(templates, modified_docx):\n",
    "    mapping = {filename:None for filename in templates}\n",
    "    \n",
    "    # Faire correspondre le nom des départements encodés vers le bon template\n",
    "    encoded_dep_name2template = {}\n",
    "    for filename in mapping:\n",
    "        raw_dep_name = filename.split('_')[-1].split('.')[0]\n",
    "        encoded_dep_name = encode_name(raw_dep_name)\n",
    "        encoded_dep_name2template[encoded_dep_name] = filename\n",
    "    assert len(encoded_dep_name2template) == 109\n",
    "    \n",
    "    # Faire correspondre le nom du département\n",
    "    duplicated_dep = []\n",
    "    for modified in modified_docx:\n",
    "        content = docx2python(modified)\n",
    "        expr_with_dep_name = content.body[0][0][0][11]\n",
    "        print(f\"Extrait de {modified} : \", expr_with_dep_name)\n",
    "        dep_name = expr_with_dep_name.split(':')[-1].strip()\n",
    "        clean_dep_name = encode_name(dep_name)\n",
    "        target_template = encoded_dep_name2template[clean_dep_name]\n",
    "        if mapping[target_template] is None:\n",
    "            mapping[target_template] = modified\n",
    "        else:\n",
    "            duplicated_dep.append(dep_name)\n",
    "            print(f\"!!! {target_template} is not None -> probably duplicated \\n----See {modified}\")\n",
    "            \n",
    "    print(\"Fiches dupliquées (à retirer manuellement puis relancer le script) :\\n\", duplicated_dep)\n",
    "    print(f\"{len(mapping)} hits\")\n",
    "    return mapping\n",
    "\n",
    "\n",
    "template2modified_docx = map_templates_to_modified_reports(templates, modified_docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les nouveaux documents contiennent le texte transposé et sous le même nom que leur template mais\n",
    "# dans un dossier différent\n",
    "\n",
    "\n",
    "def transpose_modification_to_new_reports(template2modified_docx):\n",
    "    # Transpose le texte ajouté aux documents sur le template associé. \n",
    "    # La correspondance se fait à partir du mapping (dictionnaire template -> doc modifié)\n",
    "    hit, unhit = 0, 0\n",
    "    for template_path, modified_docx_path in template2modified_docx.items():\n",
    "        output_basename = template_path.split(os.sep)[-1]\n",
    "        output_path = os.path.join(transposed_docx_dir, output_basename)\n",
    "        \n",
    "        if modified_docx_path is None:\n",
    "            unhit += 1\n",
    "            print(f'Pas de transposition pour {template_path}')\n",
    "            fill_template(template_path, output_path, volet2mesures)\n",
    "        \n",
    "        else:\n",
    "            print(f'Transpose {template_path} vers {output_path}')\n",
    "            try:\n",
    "                transpose_comments(modified_docx_path, template_path, output_path, volet2mesures)\n",
    "                hit += 1\n",
    "            except:\n",
    "                print(f\"** Transposition impossible. Génération d'une fiche vide dans {template_path}**\")\n",
    "                fill_template(template_path, output_path, volet2mesures)\n",
    "                unhit += 1\n",
    "                \n",
    "    print(f\"Hit : {hit} | Unhit : {unhit}\")\n",
    "\n",
    "\n",
    "\n",
    "transpose_modification_to_new_reports(template2modified_docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vérie si on a bien 109 rapport (1 par département)\n",
    "assert len(os.listdir(transposed_docx_dir)) == 109"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propilot",
   "language": "python",
   "name": "propilot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
