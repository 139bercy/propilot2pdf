{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import fnmatch\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_json_to_dict(url) :\n",
    "    response = urllib.request.urlopen(url)\n",
    "    my_dict = json.loads(response.read())\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(s):\n",
    "    d = {\n",
    "        \"’\": \"'\",\n",
    "        \"\\xa0\": \" \",\n",
    "        \"/\":\",\"\n",
    "        }\n",
    "    for x in d:\n",
    "        s = s.replace(x, d[x]).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {\n",
    "    \"January\" : \"Janvier\",\n",
    "\"February\": \"Février\",\n",
    "\"March\": \"Mars\",\n",
    "\"April\" : \"Avril\",\n",
    "\"May\" : \"Mai\",\n",
    "\"June\" : \"Juin\",\n",
    "\"July\" : \"Juillet\",\n",
    "\"August\" : \"Août\",\n",
    "\"September\":\"Septembre\",\n",
    "\"October\":\"Octobre\",\n",
    "\"November\":\"Novembre\",\n",
    "\"December\":\"Décembre\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxo_dep_df = pd.read_csv('refs/taxo_deps.csv', dtype={'dep':str, 'reg':str})\n",
    "taxo_dep_df['dep'] = taxo_dep_df['dep'].apply(lambda x: x.zfill(2))\n",
    "taxo_dep_df['reg'] = taxo_dep_df['reg'].apply(lambda x: x.zfill(2))\n",
    "dep_list = list(taxo_dep_df['dep'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxo_reg_df = pd.read_csv('refs/taxo_regions.csv', dtype={'reg':str})\n",
    "taxo_reg_df['reg'] = taxo_reg_df['reg'].apply(lambda x: x.zfill(2))\n",
    "reg_list = list(taxo_reg_df['reg'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailles_list = ['national', 'regional', 'departemental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propilot_path = os.path.join(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "file_list = [\n",
    "\"dim_activity\",\n",
    "\"dim_tree_nodes\",\n",
    "\"dim_top_levels\",\n",
    "\"dim_maturities\",\n",
    "\"dim_period\",\n",
    "\"dim_snapshots\",\n",
    "\"dim_effects\",\n",
    "\"dim_properties\",\n",
    "\"dim_states\",\n",
    "\"dim_structures\",\n",
    "\"fact_financials\",\n",
    "\"fact_property_values\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    for file_csv in os.listdir(propilot_path):\n",
    "        if fnmatch.fnmatch(file_csv, file + \"*.csv\"):\n",
    "            print(\"File loaded : \", file_csv)\n",
    "            df_dict[file] = pd.read_csv(os.path.join(propilot_path, file_csv), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(raw_date):\n",
    "    # Convertie un format (20210131, 2020) -> (2021-01-31, 2020)\n",
    "    str_date = str(raw_date)\n",
    "    if str_date == 'nan':\n",
    "        return raw_date\n",
    "    \n",
    "    if type(str_date) == int:\n",
    "        print(str_date)\n",
    "    if len(str_date) == 8:\n",
    "        return str_date[:4] + '-' + str_date[4:6] + '-' + str_date[6:]\n",
    "    else:\n",
    "        return str_date\n",
    "    \n",
    "\n",
    "df_dict['fact_financials']['period_id'] = df_dict['fact_financials']['period_id'].apply(lambda x: format_date(x))\n",
    "df_dict['dim_period']['period_id'] = df_dict['dim_period']['period_id'].apply(lambda x: format_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirer les lignes ayant un period quarter year commençant par 11 -> nonsense\n",
    "df_dict['dim_period'] = df_dict['dim_period'][~df_dict['dim_period']['period_quarter_year'].str.startswith('11', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df_dict[\"fact_financials\"]\n",
    "      .merge(df_dict[\"dim_tree_nodes\"], left_on=\"tree_node_id\", right_on=\"tree_node_id\") \n",
    "      .merge(df_dict[\"dim_effects\"], left_on=\"effect_id\", right_on=\"effect_id\") \n",
    "      .merge(df_dict[\"dim_states\"], left_on=\"state_id\", right_on=\"state_id\")  \n",
    "      .merge(df_dict[\"dim_period\"], left_on=\"period_id\", right_on=\"period_id\", how = 'left')\n",
    "      .merge(df_dict[\"dim_structures\"], left_on=\"structure_id\", right_on=\"structure_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_merge(facts, df):\n",
    "    num_pp_recs = facts[facts['financials_source'] == 'proPilot'].shape[0]\n",
    "    num_df_recs = df.shape[0]\n",
    "    assert num_pp_recs == num_df_recs, f\"Le nombre d'enregistrements proPilot diffèrent : avant {num_pp_recs} - après {num_df_recs}\"\n",
    "    \n",
    "\n",
    "check_data_merge(df_dict[\"fact_financials\"], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dep_code(expr):\n",
    "    nums = re.findall(r'D\\d+', expr)\n",
    "    if expr.endswith('D2A'):\n",
    "        return '2A'\n",
    "    elif expr.endswith('D2B'):\n",
    "        return '2B'\n",
    "    elif expr.endswith('E00'):\n",
    "        return '00'\n",
    "    return nums[0][1:].zfill(2) if len(nums) > 0 else None\n",
    "\n",
    "\n",
    "df['dep_code'] = df['tree_node_code'].apply(lambda x: extract_dep_code(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cols(cols, df):\n",
    "    assert set(cols).issubset(df.columns), f\"Colonnes manquantes : {set(cols) - set(df.columns)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"tree_node_name\", \"structure_name\", \"effect_id\", \"state_id\", \"period_date\", \"period_month_tri\", \"period_month_year\", \"financials_cumulated_amount\", \"dep_code\"]\n",
    "check_cols(cols, df)\n",
    "\n",
    "df=df[cols]\n",
    "df.rename(columns={\"period_month_year\":\"Date\", \"financials_cumulated_amount\":\"valeur\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forbidden_period_value = [\"Y\", \"Total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mesure_name(tree_node_name):\n",
    "    raw_mesure = tree_node_name.split('/')[1].strip() if '/' in tree_node_name else tree_node_name\n",
    "    # nettoyage de la colonne mesure, on enlève un point surnuméraire.\n",
    "    mesure = re.sub('\\.', \"\", raw_mesure)\n",
    "    mesure = clean_str(mesure)\n",
    "    return mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_single_sum_dep_equals_nat(df_copy, mesure, indic):\n",
    "    nat_values = df_copy[(df_copy['structure_name'] == 'Mesure') & \n",
    "                    (df_copy['mesure'] == mesure) &\n",
    "                    (df_copy['effect_id'] == indic)][['period_date', 'valeur']].set_index('period_date').to_dict()['valeur']\n",
    "\n",
    "    dep_indic_values = df_copy[(df_copy['structure_name'] == 'Département') & \n",
    "                            (df_copy['mesure'] == mesure) & \n",
    "                            (df_copy['effect_id'] == indic)].groupby('period_date').sum().to_dict()['valeur']\n",
    "\n",
    "    for date in dep_indic_values.keys():\n",
    "        if date not in nat_values:\n",
    "            #print(f\"-- National pas de {date}\")\n",
    "            continue\n",
    "        dep_val = round(dep_indic_values[date], 2)\n",
    "        nat_val = round(nat_values[date], 2)\n",
    "        #assert dep_val == nat_val, f\"Somme départementale : {dep_val} - Valeur récupérée nationale : {nat_val}\\n{date} - {mesure} - {indic}\"\n",
    "        # TODO : subtituer le if-else par un assert quand on aura la confirmation que les données sont cohérentes\n",
    "        if dep_val == nat_val:\n",
    "            pass\n",
    "            #print(f'ok - {mesure} - {indic} - {date}')\n",
    "        else:\n",
    "            print(f'KO - {mesure} - {indic} - {date} | {dep_val} - {nat_val}')\n",
    "            \n",
    "\n",
    "def check_sum_dep_equals_nat(df):\n",
    "    \"\"\" Ce test a été rajouté après avoir constaté des différences entre somme des départements et valeurs nationales.\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy.loc[\n",
    "                (~df_copy.period_month_tri.isin(forbidden_period_value)) &\n",
    "                (df_copy.state_id == 'Valeur Actuelle') &\n",
    "                (~df_copy.valeur.isna())].copy()\n",
    "\n",
    "    df_copy[\"mesure\"] = df_copy[\"tree_node_name\"].apply(lambda x: clean_mesure_name(x))\n",
    "\n",
    "    mesures = df_copy['mesure'].unique()\n",
    "    for mesure in mesures:\n",
    "        indics = df_copy[df_copy['mesure'] == mesure]['effect_id'].unique()\n",
    "        for indic in indics:\n",
    "            check_single_sum_dep_equals_nat(df_copy, mesure, indic)\n",
    "\n",
    "            \n",
    "check_sum_dep_equals_nat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tree_node_name.unique()\n",
    "df[\"short_indic\"] = df.effect_id.apply(lambda x: x.split(\"-\")[0].strip())\n",
    "df[\"indics\"] = df.effect_id.apply(lambda x: x.split(\"-\")[1].strip())\n",
    "\n",
    "df[df.indics == \"FFR1\"][df.structure_name == \"Département\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep = df.loc[\n",
    "    (df.structure_name == \"Département\") & \n",
    "    (~df.period_month_tri.isin(forbidden_period_value)) &\n",
    "    (df.state_id == 'Valeur Actuelle') &\n",
    "    (~df.valeur.isna())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les lignes ayant une date ultérieure à la date d'aujourd'hui\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "date_series = df_dep['period_date'].apply(lambda x: x.split('T')[0])\n",
    "df_dep['format_date'] = pd.to_datetime(date_series)\n",
    "\n",
    "df_dep = df_dep[df_dep['format_date'] <= today]\n",
    "df_dep = df_dep.drop('format_date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep[\"departement\"] = df_dep[\"tree_node_name\"].apply(lambda x: x.split(\"/\")[0].strip())\n",
    "df_dep[\"mesure\"] = df_dep[\"tree_node_name\"].apply(lambda x: x.split(\"/\")[1].strip())\n",
    "\n",
    "# nettoyage de la colonne mesure, on enlève un point surnuméraire.\n",
    "df_dep[\"mesure\"].replace(\"\\.\", \"\", regex=True,inplace=True)\n",
    "df_dep.mesure = df_dep.mesure.apply(lambda x: clean_str(x))\n",
    "\n",
    "df_dep.rename(columns={\"effect_id\":\"indicateur\"}, inplace=True)\n",
    "df_dep.indicateur = df_dep.indicateur.str.strip()\n",
    "# traduit les mois dans la colonne date\n",
    "df_dep.Date = df_dep.Date.replace(month_dict, regex=True)\n",
    "\n",
    "#df_dep.valeur.replace({\",\": \".\"}, regex=True, inplace=True)\n",
    "#df_dep.valeur = df_dep.valeur.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep[\"short_indic\"] = df_dep.indicateur.apply(lambda x: x.split(\"-\")[0].strip())\n",
    "df_dep.short_indic = df_dep.short_indic.apply(lambda x: clean_str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_single_sum_dep_equals_nat_2(df_copy, df_nat, mesure, indic):\n",
    "    nat_values = df_nat[(df_nat['mesure'] == mesure) &\n",
    "                    (df_nat['effect_id'] == indic)][['period_date', 'valeur']].set_index('period_date').to_dict()['valeur']\n",
    "\n",
    "    dep_indic_values = df_copy[(df_copy['mesure'] == mesure) & \n",
    "                                (df_copy['indicateur'] == indic)].groupby('period_date').sum().to_dict()['valeur']\n",
    "\n",
    "    for date in dep_indic_values.keys():\n",
    "        if date not in nat_values:\n",
    "            #print(f\"-- National pas de {date}\")\n",
    "            continue\n",
    "        dep_val = round(dep_indic_values[date], 2)\n",
    "        nat_val = round(nat_values[date], 2)\n",
    "        #assert dep_val == nat_val, f\"Somme départementale : {dep_val} - Valeur récupérée nationale : {nat_val}\\n{date} - {mesure} - {indic}\"\n",
    "        # TODO : subtituer le if-else par un assert quand on aura la confirmation que les données sont cohérentes\n",
    "        if dep_val == nat_val:\n",
    "            pass\n",
    "            #print(f'ok - {mesure} - {indic} - {date}')\n",
    "        else:\n",
    "            print(f'KO - {mesure} - {indic} - {date} | {dep_val} - {nat_val}')\n",
    "\n",
    "\n",
    "def check_sum_dep_equals_nat_2(df_dep, df):\n",
    "    df_nat = df.loc[(df.structure_name == \"Mesure\") & \n",
    "                (~df.period_month_tri.isin(forbidden_period_value)) &\n",
    "                (df.state_id == 'Valeur Actuelle') &\n",
    "                (~df.valeur.isna())].copy()\n",
    "\n",
    "    df_nat[\"mesure\"] = df_nat[\"tree_node_name\"].apply(lambda x: clean_mesure_name(x))\n",
    "\n",
    "    mesures = df_dep['mesure'].unique()\n",
    "    for mesure in mesures:\n",
    "        indics = df_dep[df_dep['mesure'] == mesure]['indicateur'].unique()\n",
    "        for indic in indics:\n",
    "            check_single_sum_dep_equals_nat_2(df_dep, df_nat, mesure, indic)\n",
    "            \n",
    "            \n",
    "check_sum_dep_equals_nat_2(df_dep, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_indicateur = {'Nombre de repas servis dans les restaurants universitaires au tarif à 1€' : \"Nombre de repas servis\",\n",
    " 'Montant cumulé de l’investissement total ainsi déclenché' : \"Montant cumumé de l'investissement total\",\n",
    " 'Nombre d’entreprises bénéficiaires du dispositif' : \"Nombre d'entreprises bénéficiaires\",\n",
    " 'Nombre de bâtiments Etat dont le marché de rénovation est notifié' : 'Nombre de bâtiments dont le marché de rénovation est notifié',\n",
    " 'Nombre de projets incluant une transformation de la ligne de production pour réduire son impact environnemental' : 'Nombre de projets',\n",
    " 'Nombre d\\'exploitations certifiées \"haute valeur environnementale\"' : 'Nombre d’exploitations certifiées',\n",
    " 'Emissions de gaz à effet de serre évitées sur la durée de vie des équipements' : 'Emissions de gaz à effet de serre évitées',\n",
    " 'Nombre de bonus octroyés à des véhicules électriques et hybrides rechargeables' : 'Nombre de bonus octroyés à des véhicules électriques',\n",
    " \"Quantité de matières plastiques évitées ou dont le recyclage ou l'intégration a été soutenue\" : 'Quantité de matières plastiques évitées',\n",
    " #'Montant total des travaux associés aux dossiers validés' : 'Montant total des travaux',\n",
    " 'Nombre de nouveaux projets (nouvelle ligne, extension de ligne et pôle)' : 'Nombre de nouveaux projets',\n",
    " 'Montant de l’investissement total déclenché' : 'Montant de l’investissement total',\n",
    " 'Nombre de projets de tourisme durable financés' : 'Nombre de projets de tourisme durable financés',\n",
    " 'Nombre de projets de rénovation de cathédrales et de monuments nationaux initiés' : 'Nombre de projets de rénovation',\n",
    " 'Montant total investi pour la rénovation de monuments historiques appartenant aux collectivités territoriales' :'Montant total investi pour la rénovation',\n",
    " 'Nombre de projets de rénovation de monuments historiques appartenant aux collectivités territoriales bénéficiaires initiés' : 'Nombre de projets de rénovation',\n",
    " \"Nombre de contrats de professionnalisation bénéficiaires de l'aide exceptionnelle\" : 'Nombre de contrats de professionnalisation',\n",
    " \"Nombre de contrats d'apprentissage bénéficiaires de l'aide exceptionnelle\" : 'Nombre de contrats d’apprentissage',\n",
    " \"Nombre d'aides à l'embauche des travailleurs handicapés\": \"Nombre d'aides à l'embauche des travailleurs handicapés\",\n",
    " 'Nombre de projets locaux soutenus  (rénovation, extension, création de lignes' :'Nombre de projets locaux soutenus',\n",
    " #'Nombre de dossiers MaPrimeRénov validés': 'Nombre de dossiers MaPrimeRénov bénéficiaires (\"particulier\" et \"copropriété\")',\n",
    " #'Nombre de dossiers MaPrimeRénov bénéficiaires (\"particulier\" et \"copropriété\")': 'Nombre de bénéficiaires',\n",
    " \"Nombre de dossiers MaPrimeRénov' payés\": \"Nombre de dossiers payés\",\n",
    "  \"Nombre d'entreprises bénéficiares\": \"Nombre d'entreprises bénéficiaires\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep.short_indic = df_dep.short_indic.apply(lambda x: dict_indicateur[x] if x in dict_indicateur else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep.short_indic.unique()\n",
    "df_dep[df_dep.mesure == \"MaPrimeRénov'\"].short_indic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep['indic'] = df_dep['indicateur'].apply(lambda x: x.split('-')[1].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dep.indic.unique()\n",
    "df.rename(columns={\"effect_id\":\"indicateur\"}, inplace=True)\n",
    "df.indicateur = df.indicateur.str.strip()\n",
    "\n",
    "df['indic'] = df['indicateur'].apply(lambda x: x.split('-')[1].strip())\n",
    "'RBC' in df_dep.indic.unique()\n",
    "\n",
    "\n",
    "df.period_month_tri.isin(forbidden_period_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in list(df_dep.short_indic.unique()) if len(x) > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mesures  = {\n",
    " \"Appels à projets dédiés à l'efficacité énergétique et à l'évolution des procédés en faveur de la décarbonation de l'industrie\": \"AAP Efficacité énergétique\",\n",
    " \"CIE jeunes\" : \"Contrats Initiatives Emploi (CIE) Jeunes\",\n",
    " 'France Num' : 'France Num : aide à la numérisation des TPE,PME,ETI',\n",
    " 'Guichet efficacité énergétique dans industrie' : 'Guichet efficacité énergétique',\n",
    " \"Modernisation des filières automobiles et aéronautiques\" : \"Modernisation des filières automobiles et aéronautiques\",\n",
    " \"PEC jeunes\": \"Parcours emploi compétences (PEC) Jeunes\",\n",
    " 'Relocalisation : soutien aux projets industriels dans les territoires' : 'AAP Industrie : Soutien aux projets industriels territoires',\n",
    " 'Relocalisation : sécurisation des approvisionnements critiques' : 'AAP Industrie : Sécurisation approvisionnements critiques',\n",
    " 'Renforcement des subventions de Business France (chèque export, chèque VIE)' : 'Renforcement subventions Business France',\n",
    " \"Soutien à la modernisation industrielle et renforcement des compétences dans la filière nucléaire\" : \"AAP industrie : modernisation industrielle et renforcement des compétences dans la filière nucléaire\",\n",
    " 'Soutien à la recherche aéronautique civil' :'Soutien recherche aéronautique civil',\n",
    " 'Rénovation bâtiments Etats' : 'Rénovation des bâtiments Etats (marchés notifiés)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep[\"short_mesure\"] = df_dep.mesure.apply(lambda x: dict_mesures[x] if x in dict_mesures else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dep_coherence(df):\n",
    "    assert (df['dep_code'] != df['dep']).sum() == 0, \"Incoherence des codes départementaux - voir colonne dep_code et dep.\"\n",
    "    assert df['dep'].isnull().sum() == 0, \"Certaines lignes ne possèdent pas de code département.\"\n",
    "    \n",
    "    deps_test = sorted(df['dep'].unique())\n",
    "    deps_true = sorted(taxo_dep_df['dep'].unique())\n",
    "    assert deps_test == deps_true, \"Départements ne concordent pas.\"\n",
    "    \n",
    "    assert sorted(df['libelle'].unique()) == sorted(taxo_dep_df['libelle'])\n",
    "    \n",
    "    \n",
    "def check_reg_coherence(df):\n",
    "    assert df['reg'].isnull().sum() == 0, \"Certaines lignes ne possèdent pas de code région.\"\n",
    "    \n",
    "    regs_test = sorted(df['reg'].unique())\n",
    "    regs_true = sorted(taxo_reg_df['reg'].unique())\n",
    "    assert regs_test == regs_true, \"Régions ne concordent pas.\"\n",
    "    \n",
    "    assert sorted(df['nccenr'].unique()) == sorted(taxo_reg_df['nccenr'])\n",
    "    \n",
    "    \n",
    "def check_df_dep_enr_format(df_dep_enr):\n",
    "    assert df_dep_enr.isnull().sum().sum() == 0\n",
    "    assert df_dep_enr.shape[0] == df_dep.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep_enr = df_dep.merge(taxo_dep_df[[\"dep\", \"reg\", \"libelle\"]], \n",
    "                          how=\"left\", left_on=\"dep_code\", right_on=\"dep\")\\\n",
    "                   .merge(taxo_reg_df[[\"reg\", \"nccenr\"]], how=\"left\", left_on=\"reg\", right_on=\"reg\")\n",
    "df_dep_enr.drop(columns=[\"tree_node_name\", \"structure_name\"], inplace=True)\n",
    "\n",
    "check_dep_coherence(df_dep_enr)\n",
    "check_reg_coherence(df_dep_enr)\n",
    "\n",
    "df_dep_enr.rename(columns={\"nccenr\":\"region\"}, inplace=True)\n",
    "df_dep_enr.drop(['dep_code'], axis=1, inplace=True)  # Supprime code dep utilisé pour la jointure\n",
    "\n",
    "check_df_dep_enr_format(df_dep_enr)\n",
    "df_dep_enr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep_enr.to_csv(\"pp_dep.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}