{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Permet la génération de word\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docxcompose.composer import Composer\n",
    "from docxtpl import DocxTemplate, RichText\n",
    "from docx.enum.style import WD_STYLE_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_json_to_dict(url) :\n",
    "    response = urllib.request.urlopen(url)\n",
    "    my_dict = json.loads(response.read())\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_ifnotexist(path) :\n",
    "    if not os.path.isdir(path) :\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_thousands(s):\n",
    "    # Transforme : 1000 -> 1 000\n",
    "    new_str = ''\n",
    "    for i, ch in enumerate(s[::-1], start=1):\n",
    "        new_str = ch + new_str\n",
    "        if i % 3 == 0:\n",
    "            new_str = ' ' + new_str\n",
    "    return new_str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_amount(indic, valeur):\n",
    "    if \"Montant\" in indic:\n",
    "        f_valeur = float(valeur)\n",
    "        if f_valeur > 1000000:\n",
    "            return str(round(f_valeur/1000000, 1)) + ' M€'\n",
    "        elif f_valeur > 10000:\n",
    "            return str(round(f_valeur/1000, 1)) + ' k€'\n",
    "        else:\n",
    "            return str(f_valeur)\n",
    "    else:\n",
    "        try:\n",
    "            return format_thousands(valeur.split(\".\")[0])\n",
    "        except ValueError as err:\n",
    "            print(f\"L'indicateur {indic} possède des valeurs invalides : {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailles = [\"national\", \"regional\", \"departemental\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ref départements / régions\n",
    "taxo_dep_df = pd.read_csv('refs/taxo_deps.csv', dtype={'dep':str, 'reg':str})\n",
    "taxo_dep_df['dep'] = taxo_dep_df['dep'].apply(lambda x: x.zfill(2))\n",
    "taxo_dep_df['reg'] = taxo_dep_df['reg'].apply(lambda x: x.zfill(2))\n",
    "dep_list = list(taxo_dep_df['dep'].unique())\n",
    "print('{} departements.'.format(len(dep_list)))\n",
    "\n",
    "taxo_reg_df = pd.read_csv('refs/taxo_regions.csv', dtype={'reg':str})\n",
    "taxo_reg_df['reg'] = taxo_reg_df['reg'].apply(lambda x: x.zfill(2))\n",
    "reg_list = list(taxo_reg_df['reg'].unique())\n",
    "print('{} regions.'.format(len(reg_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_dep = pd.read_csv(\"pp_dep.csv\", sep=\";\", dtype={\"reg\":str, \"dep\":str})\n",
    "\n",
    "# Suppression des espacements multiples dans la date\n",
    "pp_dep['Date'] = pp_dep.Date.apply(lambda x: re.sub(' +', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_dep['code_mesure'] = pp_dep.indicateur.apply(lambda x: x.split('-')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volet2code_mesures = {\n",
    "    'Ecologie': [\"MPR\", \"BOE\", \"DVP\", \"RBE\", \"SIL\", \"FFR\", \"FAA\"],\n",
    "    'Compétitivité': [\"IDF\", \"PIT\", \"SAC\", \"FUM\", \"SBF\", \"PAT\"],\n",
    "    'Cohésion': [\"APP\", \"PEJ\", \"CIE\", \"PEC\", \"CDP\", \"GJE\", \"SCI\", \"PTH\", \"RBC\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2short_mesure = pp_dep[['code_mesure', 'short_mesure']].set_index('code_mesure').to_dict()['short_mesure']\n",
    "\n",
    "# Ajout des clés manquantes\n",
    "#code2short_mesure['SIL'] = \"Soutien à l'investissement local (DSIL exceptionnelle)\"\n",
    "code2short_mesure['FFR'] = \"Fonds friches (projet urbain)(MTE)\"\n",
    "code2short_mesure['RBC'] = \"Rénovation thermique des bâtiments publics soutenus par la DSIL, DSID, DRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoir le nom utilisé dans pp_dep\n",
    "volet2mesures = {volet: [] for volet in volet2code_mesures}\n",
    "for volet in volet2code_mesures:\n",
    "    # Trier les mesures par ordre alphabétique\n",
    "    mesures = pp_dep[pp_dep.code_mesure.isin(volet2code_mesures[volet])].short_mesure.sort_values().unique().tolist()\n",
    "    volet2mesures[volet] = mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volet2mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de mesures attrapées\n",
    "print(len([indics for volet in volet2mesures for indics in volet2mesures[volet]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pp_reg(pp_reg):\n",
    "    assert sorted(pp_reg['reg'].unique()) == sorted(taxo_reg_df['reg'])\n",
    "    assert sorted(pp_reg['region'].unique()) == sorted(taxo_reg_df['libelle'])\n",
    "    assert sorted(pp_reg['mesure'].unique()) == sorted(pp_dep['mesure'].unique())\n",
    "    assert sorted(pp_reg['short_mesure'].unique()) == sorted(pp_dep['short_mesure'].unique())\n",
    "    \n",
    "\n",
    "def check_pp_nat(pp_nat):\n",
    "    assert sorted(pp_nat['mesure'].unique()) == sorted(pp_nat['mesure'].unique())\n",
    "    assert sorted(pp_nat['short_mesure'].unique()) == sorted(pp_nat['short_mesure'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des valeurs régionale par somme des valeurs départementales\n",
    "pp_reg = pd.pivot_table(pp_dep, index=[\"mesure\",\"short_mesure\", \"reg\",\"region\", \"Date\", \"period_date\", \"short_indic\"], values=\"valeur\", aggfunc=np.sum)\n",
    "pp_reg.rename(columns={\"reg\":\"libelle\"}, inplace=True)\n",
    "pp_reg.reset_index(inplace=True)\n",
    "check_pp_reg(pp_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des valeurs nationales par somme des valeurs régionale\n",
    "pp_nat = pd.pivot_table(pp_reg, index=[\"mesure\", \"short_mesure\", \"Date\",\"period_date\", \"short_indic\"], values=\"valeur\", aggfunc=np.sum)\n",
    "pp_nat.reset_index(inplace=True)\n",
    "check_pp_nat(pp_nat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des mesures-indicateurs à afficher dans les fiches\n",
    "code_mesures_to_keep = set([mesure for volet in volet2code_mesures for mesure in volet2code_mesures[volet]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On veut relier mesure -> indicateurs\n",
    "mesure_indics = pp_dep.groupby(['code_mesure', 'short_mesure']).agg({'short_indic': list}).reset_index()\n",
    "mesure_indics = mesure_indics[mesure_indics.code_mesure.isin(code_mesures_to_keep)]\n",
    "dict_mesure_indic = {}\n",
    "\n",
    "for i, row in mesure_indics.iterrows():\n",
    "    dict_mesure_indic[row['short_mesure']] = list(set(row['short_indic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On se restreint à certains indicateurs dans les mesures suivantes\n",
    "dict_mesure_indic['Soutien aux fonds propres des filières aéro et auto'] = [\"Nombre d'entreprises\"]\n",
    "dict_mesure_indic['AAP Industrie : Soutien aux projets industriels territoires'] = ['Nombre de TPE,PME,ETI bénéficiaires']\n",
    "dict_mesure_indic['AAP Industrie : Sécurisation approvisionnements critiques'] = ['Nombre de TPE,PME,ETI bénéficiaires']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne veut pas afficher les lignes de Prime Rénov nulles\n",
    "pp_dep = pp_dep.loc[(pp_dep.short_mesure != \"Ma Prime Rénov'\") | (pp_dep.valeur != 0) ]\n",
    "pp_reg = pp_reg.loc[(pp_reg.short_mesure != \"Ma Prime Rénov'\") | (pp_reg.valeur != 0) ]\n",
    "pp_nat = pp_nat.loc[(pp_nat.short_mesure != \"Ma Prime Rénov'\") | (pp_nat.valeur != 0) ]\n",
    "\n",
    "assert pp_dep[(pp_dep['valeur'] == 0) & (pp_dep.short_mesure == \"Ma Prime Rénov'\")].shape[0] == 0\n",
    "assert pp_reg[(pp_reg['valeur'] == 0) & (pp_reg.short_mesure == \"Ma Prime Rénov'\")].shape[0] == 0\n",
    "assert pp_nat[(pp_nat['valeur'] == 0) & (pp_nat.short_mesure == \"Ma Prime Rénov'\")].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pp_nat.duplicated(subset=['mesure','short_indic', 'Date']).sum() == 0\n",
    "assert pp_reg.duplicated(subset=['mesure','short_indic', 'Date', 'reg']).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des poids dep/reg\n",
    "pp_dep = pp_dep.merge(pp_reg[['mesure','short_indic', 'Date', 'reg', 'valeur']], \n",
    "                      on=['mesure','short_indic', 'Date', 'reg'], \n",
    "                      how='left', suffixes=('', '_reg'))\n",
    "pp_dep['poids_reg'] = pp_dep.apply(lambda x: str(round(100 * x['valeur'] / max(x['valeur_reg'], 1))) + \"%\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier qu'on a pas de pourcentages aberrants\n",
    "assert pp_dep.poids_reg.isnull().sum() == 0\n",
    "assert all(int(poids_reg[:-1]) <= 100 for poids_reg in pp_dep.poids_reg.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des poids reg/nat\n",
    "pp_reg = pp_reg.merge(pp_nat[['mesure','short_indic', 'Date', 'valeur']],\n",
    "                    on=['mesure','short_indic', 'Date'], \n",
    "                    how='left', suffixes=('', '_nat'))\n",
    "pp_reg['poids_nat'] = pp_reg.apply(lambda x: str(round(100 * x['valeur'] / max(1, x['valeur_nat']))) + \"%\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier qu'on a pas de pourcentages aberrants\n",
    "assert pp_reg.poids_nat.isnull().sum() == 0\n",
    "assert all(int(poids_nat[:-1]) <= 100 for poids_nat in pp_reg.poids_nat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_dep.valeur = pp_dep.valeur.astype(str)\n",
    "pp_dep.valeur = pp_dep.apply(lambda x: str(format_amount(x[\"short_indic\"], x[\"valeur\"])) + ' (' + x['poids_reg'] + ')', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_reg.valeur = pp_reg.valeur.astype(str)\n",
    "pp_reg.valeur = pp_reg.apply(lambda x: str(format_amount(x[\"short_indic\"], x[\"valeur\"])) + ' (' + x['poids_nat'] + ')', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_nat.valeur = pp_nat.valeur.astype(str)\n",
    "pp_nat.valeur = pp_nat.apply(lambda x: format_amount(x[\"short_indic\"], x[\"valeur\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the folders structures\n",
    "\n",
    "# For PDF\n",
    "img_dir_path = './img/'\n",
    "reports_dir_path = './reports/'\n",
    "mkdir_ifnotexist(reports_dir_path)\n",
    "\n",
    "# For words\n",
    "word_dir_path = \"reports_word\"\n",
    "word_gen_dir_path = \"reports_word/Generation_p2p\"\n",
    "mkdir_ifnotexist(word_dir_path)\n",
    "mkdir_ifnotexist(word_gen_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_charts_as_df = {\"departemental\": {dep: {} for dep in dep_list},\n",
    "                    \"national\": {'France': {}},\n",
    "                    \"regional\": {reg: {} for reg in reg_list}}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récuperer les 3 derniers mois\n",
    "months = ('Janvier', 'Février', 'Mars', 'Avril', 'Mai', 'Juin', 'Juillet', \n",
    "          'Août', 'Septembre', 'Octobre', 'Novembre', 'Décembre')\n",
    "\n",
    "today = datetime.date.today()\n",
    "last_dates_to_keep = []\n",
    "\n",
    "for i in range(1, 3+1):\n",
    "    month_name = months[(today.month-1-i) % 12]\n",
    "    year = today.year - 1 if (today.month-1-i) < 0 else today.year\n",
    "    last_dates_to_keep.append(f'{month_name} {year}')\n",
    "\n",
    "last_dates_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_values_for_missing_dates(df_plot, na_replacement):\n",
    "    # Obtention des dates à ajouter\n",
    "    missing_dates = set(last_dates_to_keep) - set(df_plot.Date)\n",
    "    sorted_missing_dates = sorted(missing_dates, key=lambda x: months.index(x.split(' ')[0]))\n",
    "    \n",
    "    # Remplissage pour les dates manquantes\n",
    "    df_complement = pd.DataFrame({col: sorted_missing_dates if col == 'Date' else na_replacement for col in df_plot.columns})\n",
    "    return pd.concat([df_plot, df_complement]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def make_pp_chart(maille, mesure, short_indics):\n",
    "    na_replacement = \"non disponible\"\n",
    "    \n",
    "    if maille == \"departemental\":\n",
    "        df = pp_dep.loc[(pp_dep.short_mesure == mesure)].sort_values(by=\"period_date\", ascending=True).copy()\n",
    "        deps = taxo_dep_df.dep.unique()  # Liste exhaustive de départements\n",
    "        \n",
    "        # Préparer un tableau par défaut à mettre quand on ne dispose d'aucune valeur\n",
    "        default = df.groupby([\"Date\", \"period_date\"]).sum().sort_values(\"period_date\", ascending=True).reset_index()\n",
    "        default[short_indics] = na_replacement\n",
    "        default = default[[\"Date\"] + short_indics]\n",
    "        default = complete_values_for_missing_dates(default, na_replacement)\n",
    "\n",
    "        for dep in deps:\n",
    "            print(f\"Plotting {mesure}-{short_indics} : departement {dep}\")\n",
    "            df_dep = df.loc[df.dep == dep]\n",
    "            if df_dep.shape[0] == 0:\n",
    "                all_charts_as_df[maille][dep][mesure] = default.T.reset_index().T  # Avoir le nom des colonnes en valeurs\n",
    "            else:\n",
    "                df_plot = pd.pivot_table(df_dep, index=['period_date', 'Date'], columns=['short_indic'], values='valeur', aggfunc='first')\n",
    "                df_plot = df_plot.reset_index().drop('period_date', axis=1)\n",
    "                df_plot = df_plot.rename_axis(None, axis=1)\n",
    "                df_plot = df_plot.fillna(na_replacement)\n",
    "                # Ajout des indicateurs/colonnes manquantes\n",
    "                cols = set(df_plot.columns).intersection(short_indics)\n",
    "                if len(cols) != len(short_indics):\n",
    "                    missing_cols = set(short_indics) - cols\n",
    "                    for missing_col in missing_cols:\n",
    "                        df_plot[missing_col] = na_replacement\n",
    "                df_plot = df_plot[['Date'] + short_indics]\n",
    "                df_plot = complete_values_for_missing_dates(df_plot, na_replacement)\n",
    "                all_charts_as_df[maille][dep][mesure] = df_plot.T.reset_index().T\n",
    "                \n",
    "            \n",
    "    elif maille == \"regional\":\n",
    "        df = pp_reg.loc[(pp_reg.short_mesure == mesure)].sort_values(by=\"period_date\", ascending=True).copy()\n",
    "        regs = taxo_dep_df.reg.unique()\n",
    "        \n",
    "        default = df.groupby([\"Date\", \"period_date\"]).sum().sort_values(\"period_date\", ascending=True).reset_index()\n",
    "        default[short_indics] = na_replacement\n",
    "        default = default[[\"Date\"] + short_indics]\n",
    "        default = complete_values_for_missing_dates(default, na_replacement)\n",
    "\n",
    "        for reg in regs:\n",
    "            print(f\"Plotting region {mesure}-{short_indics} : {reg}\")\n",
    "            df_reg = df.loc[df.reg == reg]\n",
    "            if df_reg.shape[0] == 0:\n",
    "                all_charts_as_df[maille][reg][mesure] = default.T.reset_index().T\n",
    "            else:\n",
    "                df_plot = pd.pivot_table(df_reg, index=['period_date', 'Date'], columns=['short_indic'], values='valeur', aggfunc='first')\n",
    "                df_plot = df_plot.reset_index().drop('period_date', axis=1)\n",
    "                df_plot = df_plot.rename_axis(None, axis=1)\n",
    "                df_plot = df_plot.fillna(na_replacement)\n",
    "                cols = set(df_plot.columns).intersection(short_indics)\n",
    "                if len(cols) != len(short_indics):\n",
    "                    missing_cols = set(short_indics) - cols\n",
    "                    for missing_col in missing_cols:\n",
    "                        df_plot[missing_col] = na_replacement\n",
    "                df_plot = df_plot[['Date'] + short_indics]\n",
    "                df_plot = complete_values_for_missing_dates(df_plot, na_replacement)\n",
    "                all_charts_as_df[maille][reg][mesure] = df_plot.T.reset_index().T\n",
    "            \n",
    "    elif maille == \"national\":\n",
    "        print(f\"Plotting country {mesure}-{short_indics}\")\n",
    "        df_nat = pp_nat.loc[(pp_nat.short_mesure == mesure)].sort_values(by=\"period_date\", ascending=True).copy()\n",
    "        df_plot = pd.pivot_table(df_nat, index=['period_date', 'Date'], columns=['short_indic'], values='valeur', aggfunc='first')\n",
    "        df_plot = df_plot.reset_index().drop('period_date', axis=1)\n",
    "        df_plot = df_plot.rename_axis(None, axis=1)\n",
    "        df_plot = df_plot.fillna(na_replacement)\n",
    "        df_plot = df_plot[['Date'] + short_indics]\n",
    "        df_plot = complete_values_for_missing_dates(df_plot, na_replacement)\n",
    "        all_charts_as_df[maille]['France'][mesure] = df_plot.T.reset_index().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_charts():\n",
    "    for mesure in dict_mesure_indic:\n",
    "        short_indics = dict_mesure_indic[mesure]\n",
    "        for maille in mailles :\n",
    "            make_pp_chart(maille, mesure, short_indics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "make_all_charts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_charts_exhaustivity(all_charts_as_df):\n",
    "    assert sorted(all_charts_as_df['departemental'].keys()) == sorted(taxo_dep_df['dep'])\n",
    "    assert sorted(all_charts_as_df['regional'].keys()) == sorted(taxo_reg_df['reg'])\n",
    "    assert sorted(all_charts_as_df['national'].keys()) == ['France']\n",
    "    \n",
    "    # Vérifier si des graphiques manquent.\n",
    "    for dep in taxo_dep_df['dep']:\n",
    "        assert sorted(all_charts_as_df['departemental'][dep].keys()) == sorted(dict_mesure_indic.keys()), f\"{dep}\"\n",
    "    for reg in taxo_reg_df['reg']:\n",
    "        assert sorted(all_charts_as_df['regional'][reg].keys()) == sorted(dict_mesure_indic.keys())\n",
    "    \n",
    "    assert sorted(all_charts_as_df['national']['France'].keys()) == sorted(dict_mesure_indic.keys())\n",
    "\n",
    "    \n",
    "check_charts_exhaustivity(all_charts_as_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Des lignes en trop : on est censé avoir 1 code_mesure -> 1 mesure\n",
    "ref_mesures = pd.read_excel('refs/20210601_Liste_Mesures_Liens.xlsx')\n",
    "ref_mesures = ref_mesures.fillna(method='ffill')\n",
    "ref_mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire correspondre les mesures aux urls et commentaires (absence ou présence de champs de texte)\n",
    "ref_mesures['short_mesure_in_pp_dep'] = ref_mesures.code_mesure.apply(lambda x: code2short_mesure[x])\n",
    "short_mesure2url = ref_mesures.groupby('short_mesure_in_pp_dep').agg({'url': list}).apply(lambda x: x['url'][0].strip(), axis=1).to_dict()\n",
    "short_mesure2to_comment = ref_mesures.groupby('short_mesure_in_pp_dep').agg({'commentaire': list}).apply(lambda x: x['commentaire'][0] == 'o', axis=1).to_dict()\n",
    "short_mesure2to_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des régions pour lesquelles on ne veut pas de fiche. Noms provenant de taxo_regs.csv\n",
    "L_reg_no_output = [\"00\"]  # 00 correspond à Etranger\n",
    "L_dep_no_output = ['00']\n",
    "\n",
    "\n",
    "def get_kpi(dep, short_indic, short_mesure):\n",
    "    kpi_dep = (pp_dep.loc[(pp_dep.dep == dep) \n",
    "                          & (pp_dep.short_mesure == short_mesure) \n",
    "                          & (pp_dep.short_indic == short_indic)]\n",
    "                .sort_values(by=\"period_date\", ascending=False))\n",
    "    if kpi_dep.shape[0] != 0:\n",
    "        date= kpi_dep.iloc[0].Date\n",
    "        valeur = kpi_dep.iloc[0].valeur\n",
    "    else:\n",
    "        date = pp_dep.Date.max()\n",
    "        valeur = 0\n",
    "    return date, valeur\n",
    "\n",
    "\n",
    "def creation_front_page(nom_departement):\n",
    "    doc = DocxTemplate(\"template/template_front_page.docx\")\n",
    "    today = datetime.datetime.today()\n",
    "    today_str = f\"{months[today.month-1]} {today.year}\"\n",
    "    context = {'dep': str(nom_departement), \n",
    "               'date': today_str}\n",
    "    doc.render(context)\n",
    "    name_file = \"reports_word/Generation_p2p/front_page_{}.docx\".format(nom_departement)\n",
    "    doc.save(name_file)\n",
    "    return name_file\n",
    "\n",
    "\n",
    "def encode_name(name):\n",
    "    # Normalise le nom de la mesure ou volet, notamment pour l'utiliser comme nom de code dans les commentaires\n",
    "    name = name.lower()\n",
    "    name = unidecode(name)\n",
    "    name = re.sub('[^a-z]', ' ',  name)\n",
    "    name = re.sub(' +', '', name)\n",
    "    return name\n",
    "\n",
    "\n",
    "def creation_volet_page(nom_volet, num_volet):\n",
    "    doc = DocxTemplate(\"template/template_volet.docx\")\n",
    "    context = {'volet': nom_volet, \n",
    "               'num_volet': num_volet, \n",
    "               'code_comment': \"{% for f in \" + encode_name(nom_volet) + \" %}{{ f.text }} {{ f.image }} {% endfor %}\",\n",
    "              }\n",
    "    doc.render(context)\n",
    "    name_file = \"reports_word/Generation_p2p/{}.docx\".format(nom_volet)\n",
    "    doc.save(name_file)\n",
    "    return name_file\n",
    "\n",
    "\n",
    "def delete_paragraph(paragraph):\n",
    "    p = paragraph._element\n",
    "    p.getparent().remove(p)\n",
    "    paragraph._p = paragraph._element = None\n",
    "    \n",
    "    \n",
    "def fusion_word(word1, word2, dep):\n",
    "    master = Document(word1)\n",
    "    master.add_page_break()\n",
    "    composer = Composer(master)\n",
    "    doc1 = Document(word2)\n",
    "    composer.append(doc1)\n",
    "    name_fusion = \"reports_word/Suivi_Territorial_plan_relance_{}.docx\".format(dep)\n",
    "    composer.save(name_fusion)\n",
    "    return name_fusion\n",
    "\n",
    "\n",
    "def creation_content_page(all_charts_as_df, departement, region, mesure, volet, dep_name, reg_name, num_mesure):\n",
    "    # Ouverture de template\n",
    "    if mesure in short_mesure2to_comment and short_mesure2to_comment[mesure]:\n",
    "        doc = DocxTemplate(\"template/template_content_page.docx\")\n",
    "    else:\n",
    "        doc = DocxTemplate(\"template/template_content_page_no_comment.docx\")\n",
    "    # Recuperation des datas pour les 3 scales\n",
    "    df_nat = all_charts_as_df[\"national\"][\"France\"][mesure]\n",
    "    df_reg = all_charts_as_df[\"regional\"][region][mesure]\n",
    "    df_dep = all_charts_as_df[\"departemental\"][departement][mesure]\n",
    "    \n",
    "    # Recuperation des noms des colonnes\n",
    "    col_labels = df_nat.iloc[0]\n",
    "    short_indic = dict_mesure_indic[mesure][0]\n",
    "    #date, valeur = get_kpi(departement, short_indic, mesure )\n",
    "    rt_hyperlien = RichText(f\"{num_mesure} - \", font='Marianne', size=48)\n",
    "    \n",
    "    # Si pas d'url trouvé pour la mesure, on redirige le lecteur vers la page de recherche\n",
    "    url = short_mesure2url[mesure]\n",
    "    rt_hyperlien.add(f'{mesure}', url_id=doc.build_url_id(url), \n",
    "                                    underline=True, color='#0000ff',\n",
    "                                    font='Marianne', size=48)\n",
    "    context = {\n",
    "                'mesure': rt_hyperlien,        \n",
    "                'title_table_nat' : \"Niveau National\", \n",
    "                'title_table_reg' : \"Niveau Régional\", \n",
    "                'title_table_dep' : \"Niveau Départemental\",\n",
    "                'lib_reg': reg_name, \n",
    "                'lib_dep': dep_name,\n",
    "                'col_labels' : col_labels, \n",
    "                # Les 3 lignes suivantes permettent de générer des tabeaux avec uniquement les 3 derniers mois.\n",
    "                # Prend en compte le cas ou il n'y a pas encore 3 mois de données\n",
    "                'tbl_contents_nat': [{'cols' : list(df_nat.iloc[-i-1])} for i in range(min(len(df_nat)-1, 3))],\n",
    "                'tbl_contents_reg': [{'cols' : list(df_reg.iloc[-i-1])} for i in range(min(len(df_reg)-1, 3))],\n",
    "                'tbl_contents_dep': [{'cols' : list(df_dep.iloc[-(i+1)])} for i in range(min(len(df_dep)-1, 3))],\n",
    "                'code_comment': \"{% for f in \" + encode_name(mesure) + \" %}{{ f.text }} {{ f.image }} {% endfor %}\",\n",
    "                }\n",
    "    doc.render(context)\n",
    "    name_file = \"reports_word/Generation_p2p/content_page_{}.docx\".format(mesure)\n",
    "    doc.save(name_file)\n",
    "    return name_file\n",
    "\n",
    "\n",
    "def creation_fiche(dep):\n",
    "    #departement: code departement 01:\n",
    "    #On a les variables volet2mesures, all_charts\n",
    "    reg = taxo_dep_df[taxo_dep_df['dep'] == dep].iloc[0]['reg']  # Code region\n",
    "    if reg in L_reg_no_output:\n",
    "        return False\n",
    "    num_volet, num_mesure = 1, 1\n",
    "    reg_name = taxo_reg_df[taxo_reg_df['reg'] == reg].iloc[0]['libelle']  # libelle\n",
    "    dep_name = taxo_dep_df[taxo_dep_df['dep'] == dep].iloc[0]['libelle']\n",
    "    name_fusion = creation_front_page(dep_name)\n",
    "    for volet in list(volet2mesures.keys()):  # 3 itérations, dep_name, reg_name\n",
    "        name_volet = creation_volet_page(volet, num_volet)\n",
    "        name_fusion = fusion_word(name_fusion, name_volet, dep_name)\n",
    "        liste_mesure = volet2mesures[volet]\n",
    "        num_volet += 1\n",
    "        for mesure in liste_mesure:\n",
    "            name_content = creation_content_page(all_charts_as_df, dep, reg, mesure, volet, dep_name, reg_name, num_mesure)\n",
    "            name_fusion = fusion_word(name_fusion, name_content, dep_name)\n",
    "            num_mesure += 1\n",
    "    return name_fusion\n",
    "            \n",
    "\n",
    "\n",
    "def create_all_dep():\n",
    "    list_all_dep = taxo_dep_df[~taxo_dep_df[\"dep\"].isin(L_dep_no_output)].dep\n",
    "    for dep in list_all_dep:\n",
    "        docx_path = creation_fiche(dep)\n",
    "        print(dep + ' ' + docx_path)\n",
    "        doc = Document(docx_path)\n",
    "\n",
    "        # Retirer le double espacement après les tableaux\n",
    "        for paragraph in doc.paragraphs:\n",
    "            # Retirer les lignes vides après les tableaux en fin de page : elles sont reconnues par la taille \n",
    "            # de la police <= 2 où ne possède pas de run.\n",
    "            if paragraph.text.__len__() == 0 and (any(run.font.size <= Pt(2) for run in paragraph.runs if run.font.size is not None) or \n",
    "                                                  (all(run.font.size is None for run in paragraph.runs))):\n",
    "                delete_paragraph(paragraph)\n",
    "        doc.save(docx_path)\n",
    "        \n",
    "        # Réduire la taille du paragraphe après le dernier tableau de chaque page\n",
    "        # Cela permet d'éviter de créer une nouvelle page quand le texte devient trop long\n",
    "        doc = Document(docx_path)\n",
    "        styles = doc.styles\n",
    "        style = styles.add_style('Custom_style', WD_STYLE_TYPE.PARAGRAPH)\n",
    "        style.font.size = Pt(2)\n",
    "        for paragraph in doc.paragraphs:\n",
    "            if len(paragraph.text) == 1:\n",
    "                paragraph.style = doc.styles['Custom_style']\n",
    "        doc.save(docx_path)\n",
    "\n",
    "        \n",
    "# Lance la génération dans le dossier reports_word\n",
    "create_all_dep()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_num_docx_created():\n",
    "    num_test = len([fn for fn in os.listdir('reports_word') if \"Suivi\" in fn])\n",
    "    num_true = taxo_dep_df['dep'].shape[0]\n",
    "    # num_true-1 car on enlève le département Etranger \"00\"\n",
    "    assert num_test == num_true-1, f\"{num_test} -- {num_true-1}\"\n",
    "    \n",
    "check_num_docx_created()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propilot",
   "language": "python",
   "name": "propilot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
