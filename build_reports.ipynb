{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Permet la génération de word\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docxcompose.composer import Composer\n",
    "from docxtpl import DocxTemplate, RichText\n",
    "from docx.enum.style import WD_STYLE_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_json_to_dict(url) :\n",
    "    response = urllib.request.urlopen(url)\n",
    "    my_dict = json.loads(response.read())\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir_ifnotexist(path) :\n",
    "    if not os.path.isdir(path) :\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_thousands(s):\n",
    "    # Transforme : 1000 -> 1 000\n",
    "    new_str = ''\n",
    "    for i, ch in enumerate(s[::-1], start=1):\n",
    "        new_str = ch + new_str\n",
    "        if i % 3 == 0:\n",
    "            new_str = ' ' + new_str\n",
    "    return new_str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_amount(indic, valeur):\n",
    "    if \"Montant\" in indic:\n",
    "        f_valeur = float(valeur)\n",
    "        if f_valeur > 1000000:\n",
    "            return str(round(f_valeur/1000000, 1)) + ' M€'\n",
    "        elif f_valeur > 10000:\n",
    "            return str(round(f_valeur/1000, 1)) + ' k€'\n",
    "        else:\n",
    "            return str(f_valeur)\n",
    "    else:\n",
    "        try:\n",
    "            return format_thousands(valeur.split(\".\")[0])\n",
    "        except ValueError as err:\n",
    "            print(f\"L'indicateur {indic} possède des valeurs invalides : {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailles = [\"national\", \"regional\", \"departemental\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ref départements / régions\n",
    "taxo_dep_df = pd.read_csv('refs/taxo_deps.csv', dtype={'dep':str, 'reg':str})\n",
    "taxo_dep_df['dep'] = taxo_dep_df['dep'].apply(lambda x: x.zfill(2))\n",
    "taxo_dep_df['reg'] = taxo_dep_df['reg'].apply(lambda x: x.zfill(2))\n",
    "dep_list = list(taxo_dep_df['dep'].unique())\n",
    "print('{} departements.'.format(len(dep_list)))\n",
    "\n",
    "taxo_reg_df = pd.read_csv('refs/taxo_regions.csv', dtype={'reg':str})\n",
    "taxo_reg_df['reg'] = taxo_reg_df['reg'].apply(lambda x: x.zfill(2))\n",
    "reg_list = list(taxo_reg_df['reg'].unique())\n",
    "print('{} regions.'.format(len(reg_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_dep = pd.read_csv(\"pp_dep.csv\", sep=\";\", dtype={\"reg\":str, \"dep\":str})\n",
    "\n",
    "# Suppression des espacements multiples dans la date\n",
    "pp_dep['Date'] = pp_dep.Date.apply(lambda x: re.sub(' +', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_dep['code_mesure'] = pp_dep.indicateur.apply(lambda x: x.split('-')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volet2code_mesures = {\n",
    "    'Ecologie': [\"MPR2\", \"MPR4\", \"BOE1\", \"DVP1\", \"RBC3\", \"RBE1\", \"AEA1\", \"FFR1\", \"BPI1\", \"BPI2\"],  #MPR et BPI x2\n",
    "    'Compétitivité': [\"IDF1\", \"IDF2\", \"IDF3\", \"PIT3\", \"SAC3\", \"FUM1\", \"SFC1\", \"SBF1\"],\n",
    "    'Cohésion': [\"APP1\", \"PEJ1\", \"CIE1\", \"PEC1\", \"CDP1\", \"GJE1\", \"SCI1\", \"PTH1\", \"SIL1\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2short_mesure = pp_dep[['code_mesure', 'short_mesure']].set_index('code_mesure').to_dict()['short_mesure']\n",
    "\n",
    "# Ajout des clés manquantes\n",
    "code2short_mesure['SIL1'] = \"Soutien à l'investissement local (DSIL exceptionnelle)\"\n",
    "code2short_mesure['RBC3'] = \"Rénovation thermique des bâtiments publics soutenus par la DSIL, DSID, DRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoir le nom des mesures utilisé dans pp_dep séparés par volet\n",
    "volet2mesures = {volet: [] for volet in volet2code_mesures}\n",
    "for volet in volet2code_mesures:\n",
    "    # Trier les mesures par ordre alphabétique\n",
    "    mesures = pp_dep[pp_dep.code_mesure.isin(volet2code_mesures[volet])].short_mesure.sort_values().unique().tolist()\n",
    "    volet2mesures[volet] = mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pp_reg(pp_reg):\n",
    "    assert sorted(pp_reg['reg'].unique()) == sorted(taxo_reg_df['reg'])\n",
    "    assert sorted(pp_reg['region'].unique()) == sorted(taxo_reg_df['libelle'])\n",
    "    assert sorted(pp_reg['mesure'].unique()) == sorted(pp_dep['mesure'].unique())\n",
    "    assert sorted(pp_reg['short_mesure'].unique()) == sorted(pp_dep['short_mesure'].unique())\n",
    "    \n",
    "\n",
    "def check_pp_nat(pp_nat):\n",
    "    assert sorted(pp_nat['mesure'].unique()) == sorted(pp_nat['mesure'].unique())\n",
    "    assert sorted(pp_nat['short_mesure'].unique()) == sorted(pp_nat['short_mesure'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des valeurs régionale par somme des valeurs départementales\n",
    "pp_reg = pd.pivot_table(pp_dep, index=[\"mesure\",\"short_mesure\", \"reg\",\"region\", \"Date\", \"period_date\", \"short_indic\"], values=\"valeur\", aggfunc=np.sum)\n",
    "pp_reg.rename(columns={\"reg\":\"libelle\"}, inplace=True)\n",
    "pp_reg.reset_index(inplace=True)\n",
    "check_pp_reg(pp_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des valeurs nationales par somme des valeurs régionale\n",
    "pp_nat = pd.pivot_table(pp_reg, index=[\"mesure\", \"short_mesure\", \"Date\",\"period_date\", \"short_indic\"], values=\"valeur\", aggfunc=np.sum)\n",
    "pp_nat.reset_index(inplace=True)\n",
    "check_pp_nat(pp_nat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des mesures-indicateurs à afficher dans les fiches\n",
    "code_mesures_to_keep = set([mesure for volet in volet2code_mesures for mesure in volet2code_mesures[volet]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On veut relier mesure -> indicateurs\n",
    "mesure_indics = pp_dep.groupby(['code_mesure', 'short_mesure']).agg({'short_indic': list}).reset_index()\n",
    "mesure_indics = mesure_indics[mesure_indics.code_mesure.isin(code_mesures_to_keep)]\n",
    "dict_mesure_indic = {}\n",
    "\n",
    "for i, row in mesure_indics.iterrows():\n",
    "    dict_mesure_indic[row['short_mesure']] = list(set(row['short_indic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On se restreint à certains indicateurs dans les mesures suivantes\n",
    "dict_mesure_indic['Soutien aux fonds propres des filières automobiles et aéronautiques'] = [\"Nombre d'entreprises\"]\n",
    "dict_mesure_indic['AAP Industrie : Soutien aux projets industriels territoires'] = ['Nombre de TPE,PME,ETI bénéficiaires']\n",
    "dict_mesure_indic['AAP Industrie : Sécurisation approvisionnements critiques'] = ['Nombre de TPE,PME,ETI bénéficiaires']\n",
    "\n",
    "# Rajout de restriction ICI\n",
    "dict_mesure_indic[\"MaPrimeRénov'\"] = ['Nombre de dossiers MaPrimeRénov validés', 'Montant total des travaux associés aux dossiers validés']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne veut pas afficher les lignes de Prime Rénov nulles\n",
    "pp_dep = pp_dep.loc[(pp_dep.short_mesure != \"Ma Prime Rénov'\") | (pp_dep.valeur != 0) ]\n",
    "pp_reg = pp_reg.loc[(pp_reg.short_mesure != \"Ma Prime Rénov'\") | (pp_reg.valeur != 0) ]\n",
    "pp_nat = pp_nat.loc[(pp_nat.short_mesure != \"Ma Prime Rénov'\") | (pp_nat.valeur != 0) ]\n",
    "\n",
    "assert pp_dep[(pp_dep['valeur'] == 0) & (pp_dep.short_mesure == \"Ma Prime Rénov'\")].shape[0] == 0\n",
    "assert pp_reg[(pp_reg['valeur'] == 0) & (pp_reg.short_mesure == \"Ma Prime Rénov'\")].shape[0] == 0\n",
    "assert pp_nat[(pp_nat['valeur'] == 0) & (pp_nat.short_mesure == \"Ma Prime Rénov'\")].shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pp_nat.duplicated(subset=['mesure','short_indic', 'Date']).sum() == 0\n",
    "assert pp_reg.duplicated(subset=['mesure','short_indic', 'Date', 'reg']).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des poids dep/reg\n",
    "pp_dep = pp_dep.merge(pp_reg[['mesure','short_indic', 'Date', 'reg', 'valeur']], \n",
    "                      on=['mesure','short_indic', 'Date', 'reg'], \n",
    "                      how='left', suffixes=('', '_reg'))\n",
    "pp_dep['poids_reg'] = pp_dep.apply(lambda x: str(round(100 * x['valeur'] / max(x['valeur_reg'], 1))) + \"%\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier qu'on a pas de pourcentages aberrants\n",
    "assert pp_dep.poids_reg.isnull().sum() == 0\n",
    "assert all(int(poids_reg[:-1]) <= 100 for poids_reg in pp_dep.poids_reg.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des poids reg/nat\n",
    "pp_reg = pp_reg.merge(pp_nat[['mesure','short_indic', 'Date', 'valeur']],\n",
    "                    on=['mesure','short_indic', 'Date'], \n",
    "                    how='left', suffixes=('', '_nat'))\n",
    "pp_reg['poids_nat'] = pp_reg.apply(lambda x: str(round(100 * x['valeur'] / max(1, x['valeur_nat']))) + \"%\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier qu'on a pas de pourcentages aberrants\n",
    "assert pp_reg.poids_nat.isnull().sum() == 0\n",
    "assert all(int(poids_nat[:-1]) <= 100 for poids_nat in pp_reg.poids_nat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_dep.valeur = pp_dep.valeur.astype(str)\n",
    "pp_dep.valeur = pp_dep.apply(lambda x: str(format_amount(x[\"short_indic\"], x[\"valeur\"])) + ' (' + x['poids_reg'] + ')', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_reg.valeur = pp_reg.valeur.astype(str)\n",
    "pp_reg.valeur = pp_reg.apply(lambda x: str(format_amount(x[\"short_indic\"], x[\"valeur\"])) + ' (' + x['poids_nat'] + ')', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_nat.valeur = pp_nat.valeur.astype(str)\n",
    "pp_nat.valeur = pp_nat.apply(lambda x: format_amount(x[\"short_indic\"], x[\"valeur\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des dossiers pour stocker les fiches\n",
    "\n",
    "# Dossier imgs avec les logos\n",
    "img_dir_path = './img/'\n",
    "\n",
    "# Dossiers fiches\n",
    "word_dir_path = \"reports_word\"\n",
    "word_gen_dir_path = \"reports_word/Generation_p2p\"\n",
    "mkdir_ifnotexist(word_dir_path)\n",
    "mkdir_ifnotexist(word_gen_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_charts_as_df = {\"departemental\": {dep: {} for dep in dep_list},\n",
    "                    \"national\": {'France': {}},\n",
    "                    \"regional\": {reg: {} for reg in reg_list}}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_charts_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récuperer les 3 derniers mois à insérer dans les fiches\n",
    "months = ('Janvier', 'Février', 'Mars', 'Avril', 'Mai', 'Juin', 'Juillet', \n",
    "          'Août', 'Septembre', 'Octobre', 'Novembre', 'Décembre')\n",
    "\n",
    "today = datetime.date.today()\n",
    "last_dates_to_keep = []\n",
    "\n",
    "modulo = 2 # On veut les 3 derniers mois pleins. Si on génère les fiches en Juillet, et que l'on ne veut pas de Juin, passez modulo à 2\n",
    "\n",
    "for i in range(1, 3+1):\n",
    "    month_name = months[(today.month-modulo-i) % 12]\n",
    "    year = today.year - 1 if (today.month-1-i) < 0 else today.year\n",
    "    last_dates_to_keep.append(f'{month_name} {year}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_values_for_missing_dates(df_plot, na_replacement):\n",
    "    # Obtention des dates à ajouter\n",
    "    missing_dates = set(last_dates_to_keep) - set(df_plot.Date)\n",
    "    sorted_missing_dates = sorted(missing_dates, key=lambda x: months.index(x.split(' ')[0]))\n",
    "    dict_conv = {\"Mars 2021\": '2021-03-31T00:00:00.0000000',\n",
    "                 \"Avril 2021\": '2021-04-30T00:00:00.0000000',\n",
    "                 \"Mai 2021\": '2021-05-31T00:00:00.0000000'}\n",
    "    # Remplissage pour les dates manquantes\n",
    "    df_complement = pd.DataFrame({col: sorted_missing_dates if col == 'Date' else na_replacement for col in df_plot.columns})\n",
    "\n",
    "    df_complement['period_date'] = '2021-05-31T00:00:00.0000000'\n",
    "    if len(sorted_missing_dates) != 0:\n",
    "        for element in sorted_missing_dates:\n",
    "            df_complement['period_date'] = np.where(df_complement.Date == element, dict_conv[element], df_complement['period_date'])\n",
    "\n",
    "    return pd.concat([df_plot, df_complement]).reset_index(drop=True)\n",
    "\n",
    "def make_pp_chart(maille, mesure, short_indics):\n",
    "    na_replacement = 0\n",
    "    \n",
    "    if maille == \"departemental\":\n",
    "        df = pp_dep.loc[(pp_dep.short_mesure == mesure)].sort_values(by=\"period_date\", ascending=True).copy()\n",
    "        deps = taxo_dep_df.dep.unique()  # Liste exhaustive de départements\n",
    "        \n",
    "        # Préparer un tableau par défaut à mettre quand on ne dispose d'aucune valeur\n",
    "        default = df.groupby([\"Date\", \"period_date\"]).sum().sort_values(\"period_date\", ascending=True).reset_index()\n",
    "        default[short_indics] = na_replacement\n",
    "        default = default[[\"Date\", \"period_date\"] + short_indics]\n",
    "        default = complete_values_for_missing_dates(default, na_replacement)\n",
    "        default = default.reset_index()\n",
    "        default = default.sort_values(by = 'period_date', ascending=True)\n",
    "        default = default.drop('period_date', axis=1)\n",
    "        default = default.drop('index', axis=1)\n",
    "\n",
    "        for dep in deps:\n",
    "            print(f\"Plotting {mesure}-{short_indics} : departement {dep}\")\n",
    "            df_dep = df.loc[df.dep == dep]\n",
    "            if df_dep.shape[0] == 0:\n",
    "                all_charts_as_df[maille][dep][mesure] = default.T.reset_index().T  # Avoir le nom des colonnes en valeurs\n",
    "            else:\n",
    "                df_plot = pd.pivot_table(df_dep, index=['period_date', 'Date'], columns=['short_indic'], values='valeur', aggfunc='first')\n",
    "                df_plot = df_plot.reset_index().sort_values(by = 'period_date')\n",
    "                df_plot = df_plot.rename_axis(None, axis=1)\n",
    "                df_plot = df_plot.fillna(na_replacement)\n",
    "                # Ajout des indicateurs/colonnes manquantes\n",
    "                cols = set(df_plot.columns).intersection(short_indics)\n",
    "                if len(cols) != len(short_indics):\n",
    "                    missing_cols = set(short_indics) - cols\n",
    "                    for missing_col in missing_cols:\n",
    "                        df_plot[missing_col] = na_replacement\n",
    "                df_plot = df_plot[['Date', 'period_date'] + short_indics]\n",
    "                df_plot = complete_values_for_missing_dates(df_plot, na_replacement)\n",
    "                df_plot = df_plot.reset_index().sort_values(by = 'period_date')\n",
    "                df_plot = df_plot.drop('period_date', axis=1)\n",
    "                df_plot = df_plot.drop('index', axis=1)\n",
    "                all_charts_as_df[maille][dep][mesure] = df_plot.T.reset_index().T\n",
    "                \n",
    "            \n",
    "    elif maille == \"regional\":\n",
    "        df = pp_reg.loc[(pp_reg.short_mesure == mesure)].sort_values(by=\"period_date\", ascending=True).copy()\n",
    "        regs = taxo_dep_df.reg.unique()\n",
    "        \n",
    "        default = df.groupby([\"Date\", \"period_date\"]).sum().sort_values(\"period_date\", ascending=True).reset_index()\n",
    "        default[short_indics] = na_replacement\n",
    "        default = default[[\"Date\", \"period_date\"] + short_indics]\n",
    "        default = complete_values_for_missing_dates(default, na_replacement)\n",
    "        default = default.reset_index()\n",
    "        default = default.sort_values(by = 'period_date', ascending=True)\n",
    "        default = default.drop('period_date', axis=1)\n",
    "        default = default.drop('index', axis=1)\n",
    "\n",
    "        for reg in regs:\n",
    "            print(f\"Plotting region {mesure}-{short_indics} : {reg}\")\n",
    "            df_reg = df.loc[df.reg == reg]\n",
    "            if df_reg.shape[0] == 0:\n",
    "                all_charts_as_df[maille][reg][mesure] = default.T.reset_index().T\n",
    "            else:\n",
    "                df_plot = pd.pivot_table(df_reg, index=['period_date', 'Date'], columns=['short_indic'], values='valeur', aggfunc='first')\n",
    "                df_plot = df_plot.reset_index()\n",
    "                df_plot = df_plot.rename_axis(None, axis=1)\n",
    "                df_plot = df_plot.fillna(na_replacement)\n",
    "                cols = set(df_plot.columns).intersection(short_indics)\n",
    "                if len(cols) != len(short_indics):\n",
    "                    missing_cols = set(short_indics) - cols\n",
    "                    for missing_col in missing_cols:\n",
    "                        df_plot[missing_col] = na_replacement\n",
    "                df_plot = df_plot[['Date', 'period_date'] + short_indics]\n",
    "                df_plot = complete_values_for_missing_dates(df_plot, na_replacement)\n",
    "                df_plot = df_plot.reset_index().sort_values(by = 'period_date')\n",
    "                df_plot = df_plot.drop('period_date', axis=1)\n",
    "                df_plot = df_plot.drop('index', axis=1)\n",
    "                all_charts_as_df[maille][reg][mesure] = df_plot.T.reset_index().T\n",
    "            \n",
    "    elif maille == \"national\":\n",
    "        print(f\"Plotting country {mesure}-{short_indics}\")\n",
    "        df_nat = pp_nat.loc[(pp_nat.short_mesure == mesure)].sort_values(by=\"period_date\", ascending=True).copy()\n",
    "        df_plot = pd.pivot_table(df_nat, index=['period_date', 'Date'], columns=['short_indic'], values='valeur', aggfunc='first')\n",
    "        df_plot = df_plot.reset_index()\n",
    "        df_plot = df_plot.rename_axis(None, axis=1)\n",
    "        df_plot = df_plot.fillna(na_replacement)\n",
    "        df_plot = df_plot[['Date', 'period_date'] + short_indics]\n",
    "        df_plot = complete_values_for_missing_dates(df_plot, na_replacement)\n",
    "        df_plot = df_plot.reset_index().sort_values(by = 'period_date')\n",
    "        df_plot = df_plot.drop('period_date', axis=1)\n",
    "        df_plot = df_plot.drop('index', axis=1)\n",
    "        all_charts_as_df[maille]['France'][mesure] = df_plot.T.reset_index().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_charts():\n",
    "    for mesure in dict_mesure_indic:\n",
    "        short_indics = dict_mesure_indic[mesure]\n",
    "        for maille in mailles :\n",
    "            make_pp_chart(maille, mesure, short_indics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "make_all_charts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_charts_exhaustivity(all_charts_as_df):\n",
    "    assert sorted(all_charts_as_df['departemental'].keys()) == sorted(taxo_dep_df['dep'])\n",
    "    assert sorted(all_charts_as_df['regional'].keys()) == sorted(taxo_reg_df['reg'])\n",
    "    assert sorted(all_charts_as_df['national'].keys()) == ['France']\n",
    "    \n",
    "    # Vérifier si des graphiques manquent.\n",
    "    for dep in taxo_dep_df['dep']:\n",
    "        assert sorted(all_charts_as_df['departemental'][dep].keys()) == sorted(dict_mesure_indic.keys()), f\"{dep}\"\n",
    "    for reg in taxo_reg_df['reg']:\n",
    "        assert sorted(all_charts_as_df['regional'][reg].keys()) == sorted(dict_mesure_indic.keys())\n",
    "    \n",
    "    assert sorted(all_charts_as_df['national']['France'].keys()) == sorted(dict_mesure_indic.keys())\n",
    "\n",
    "    \n",
    "check_charts_exhaustivity(all_charts_as_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer le dataframe des mesures à insérer\n",
    "ref_mesures2 = pd.read_excel('refs/20210630_Liste_Mesures-Ficheparlementaire.xlsx')\n",
    "ref_mesures2.drop([\"Unnamed: 5\", \"Mesures suivie dans le TdB grand public\"], axis = 1, inplace=True)\n",
    "ref_mesures2.drop([27], inplace=True)\n",
    "ref_mesures2 = ref_mesures2.rename(columns={\"Liens hypertexte\": \"url\",\n",
    "                                            \"Numéro indicateur\": \"code_mesure\"})\n",
    "for i in range(27):\n",
    "    if i < 10:\n",
    "        ref_mesures2[\"Volet\"].loc[i] = ref_mesures2[\"Volet\"].loc[0]\n",
    "    elif i < 18:\n",
    "        ref_mesures2[\"Volet\"].loc[i] = ref_mesures2[\"Volet\"].loc[10]\n",
    "    else:\n",
    "        ref_mesures2[\"Volet\"].loc[i] = ref_mesures2[\"Volet\"].loc[18]\n",
    "\n",
    "ref_mesures2[\"Mesures\"].iloc[1] = ref_mesures2[\"Mesures\"].iloc[0]\n",
    "ref_mesures2[\"Mesures\"].iloc[9] = ref_mesures2[\"Mesures\"].iloc[8]\n",
    "ref_mesures2[\"Mesures\"].iloc[11] = ref_mesures2[\"Mesures\"].iloc[10]\n",
    "ref_mesures2[\"Mesures\"].iloc[12] = ref_mesures2[\"Mesures\"].iloc[10]\n",
    "\n",
    "ref_mesures2[\"url\"].iloc[1] = ref_mesures2[\"url\"].iloc[0]\n",
    "ref_mesures2[\"url\"].iloc[9] = ref_mesures2[\"url\"].iloc[8]\n",
    "ref_mesures2[\"url\"].iloc[11] = ref_mesures2[\"url\"].iloc[10]\n",
    "ref_mesures2[\"url\"].iloc[12] = ref_mesures2[\"url\"].iloc[10]\n",
    "\n",
    "ref_mesures2[\"url\"].iloc[16] = \"https://www.economie.gouv.fr/files/files/directions_services/plan-de-relance/Guide-mesures-relance-exportations.pdf\"\n",
    "ref_mesures2[\"url\"].iloc[17] = \"https://www.economie.gouv.fr/files/files/directions_services/plan-de-relance/Guide-mesures-relance-exportations.pdf\"\n",
    "\n",
    "ref_mesures2[\"code_mesure\"].iloc[18] = \"APP\"\n",
    "L_com = [\"RBE\",\n",
    "         \"FAA\",\n",
    "         \"PIT\",\n",
    "         \"SAC\",\n",
    "         \"FUM\",\n",
    "         \"SBF\"]\n",
    "ref_mesures2[\"commentaire\"] = \"n\"\n",
    "for i in range(27):\n",
    "    for j in range(len(L_com)):\n",
    "        if L_com[j] in ref_mesures2[\"code_mesure\"].iloc[i]:\n",
    "            ref_mesures2[\"commentaire\"].iloc[i] = \"o\"\n",
    "\n",
    "# Retravail de la colonne code_mesure\n",
    "code = [\"MPR4\", \"MPR2\", \"BOE1\", \"DVP1\", \"RBC3\", \"RBE1\", \"AEA1\", \"FFR1\", \"BPI1\", \"BPI2\", \"IDF3\", \"IDF1\", \"IDF2\", \"PIT3\", \"SAC3\", \"FUM1\", \"SFC1\", \"SBF1\",\n",
    " \"APP1\", \"PEJ1\", \"CIE1\", \"PEC1\", \"CDP1\", \"GJE1\", \"SCI1\", \"PTH1\", \"SIL1\"]\n",
    "\n",
    "for i in range(len(code)):\n",
    "    ref_mesures2[\"code_mesure\"].iloc[i] = code[i]\n",
    "ref_mesures = ref_mesures2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mesures['short_mesure_in_pp_dep'] = ref_mesures.code_mesure.apply(lambda x: code2short_mesure[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire correspondre les mesures aux urls et commentaires (absence ou présence de champs de texte)\n",
    "ref_mesures['short_mesure_in_pp_dep'] = ref_mesures.code_mesure.apply(lambda x: code2short_mesure[x])\n",
    "short_mesure2url = ref_mesures.groupby('short_mesure_in_pp_dep').agg({'url': list}).apply(lambda x: x['url'][0].strip(), axis=1).to_dict()\n",
    "short_mesure2to_comment = ref_mesures.groupby('short_mesure_in_pp_dep').agg({'commentaire': list}).apply(lambda x: x['commentaire'][0] == 'o', axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des régions pour lesquelles on ne veut pas de fiche. Noms provenant de taxo_regs.csv\n",
    "L_reg_no_output = [\"00\"]  # 00 correspond à Etranger\n",
    "L_dep_no_output = ['00']\n",
    "\n",
    "\n",
    "def get_kpi(dep, short_indic, short_mesure):\n",
    "    kpi_dep = (pp_dep.loc[(pp_dep.dep == dep) \n",
    "                          & (pp_dep.short_mesure == short_mesure) \n",
    "                          & (pp_dep.short_indic == short_indic)]\n",
    "                .sort_values(by=\"period_date\", ascending=False))\n",
    "    if kpi_dep.shape[0] != 0:\n",
    "        date= kpi_dep.iloc[0].Date\n",
    "        valeur = kpi_dep.iloc[0].valeur\n",
    "    else:\n",
    "        date = pp_dep.Date.max()\n",
    "        valeur = 0\n",
    "    return date, valeur\n",
    "\n",
    "\n",
    "def creation_front_page(nom_departement):\n",
    "    doc = DocxTemplate(\"template/template_front_page.docx\")\n",
    "    today = datetime.datetime.today()\n",
    "    today_str = f\"{months[today.month-1]} {today.year}\"\n",
    "    context = {'dep': str(nom_departement), \n",
    "               'date': 'Mai 2021'}  # A remplacer par today_str plus tard. On nous demande de mettre Mai 2021 ------------------------------------ !!!!!!!!!!!!!!!!!!!!\n",
    "    doc.render(context)\n",
    "    name_file = \"reports_word/Generation_p2p/front_page_{}.docx\".format(nom_departement)\n",
    "    doc.save(name_file)\n",
    "    return name_file\n",
    "\n",
    "\n",
    "def encode_name(name):\n",
    "    # Normalise le nom de la mesure ou volet, notamment pour l'utiliser comme nom de code dans les commentaires\n",
    "    name = name.lower()\n",
    "    name = unidecode(name)\n",
    "    name = re.sub('[^a-z]', ' ',  name)\n",
    "    name = re.sub(' +', '', name)\n",
    "    return name\n",
    "\n",
    "\n",
    "def creation_volet_page(nom_volet, num_volet):\n",
    "    doc = DocxTemplate(\"template/template_volet.docx\")\n",
    "    context = {'volet': nom_volet, \n",
    "               'num_volet': num_volet, \n",
    "               'code_comment': \"{% for f in \" + encode_name(nom_volet) + \" %}{{ f.text }} {{ f.image }} {% endfor %}\",\n",
    "              }\n",
    "    doc.render(context)\n",
    "    name_file = \"reports_word/Generation_p2p/{}.docx\".format(nom_volet)\n",
    "    doc.save(name_file)\n",
    "    return name_file\n",
    "\n",
    "\n",
    "def delete_paragraph(paragraph):\n",
    "    p = paragraph._element\n",
    "    p.getparent().remove(p)\n",
    "    paragraph._p = paragraph._element = None\n",
    "    \n",
    "    \n",
    "def fusion_word(word1, word2, dep):\n",
    "    master = Document(word1)\n",
    "    master.add_page_break()\n",
    "    composer = Composer(master)\n",
    "    doc1 = Document(word2)\n",
    "    composer.append(doc1)\n",
    "    name_fusion = \"reports_word/Suivi_Territorial_plan_relance_{}.docx\".format(dep)\n",
    "    composer.save(name_fusion)\n",
    "    return name_fusion\n",
    "\n",
    "\n",
    "def creation_content_page(all_charts_as_df, departement, region, mesure, volet, dep_name, reg_name, num_mesure):\n",
    "    # Ouverture de template\n",
    "    if mesure in short_mesure2to_comment and short_mesure2to_comment[mesure]:\n",
    "        doc = DocxTemplate(\"template/template_content_page.docx\")\n",
    "    else:\n",
    "        doc = DocxTemplate(\"template/template_content_page_no_comment.docx\")\n",
    "    # Recuperation des datas pour les 3 scales\n",
    "    df_nat = all_charts_as_df[\"national\"][\"France\"][mesure]\n",
    "    df_reg = all_charts_as_df[\"regional\"][region][mesure]\n",
    "    df_dep = all_charts_as_df[\"departemental\"][departement][mesure]\n",
    "    \n",
    "    # Recuperation des noms des colonnes\n",
    "    col_labels = df_nat.iloc[0]\n",
    "    short_indic = dict_mesure_indic[mesure][0]\n",
    "    rt_hyperlien = RichText(f\"{num_mesure} - \", font='Marianne', size=40, color='#00a65d')\n",
    "    \n",
    "    # Si pas d'url trouvé pour la mesure, on redirige le lecteur vers la page de recherche decommenter lors de la maj du xlsx\n",
    "    url = short_mesure2url[mesure]\n",
    "    rt_hyperlien.add(f'{mesure}', url_id=doc.build_url_id(url), \n",
    "                                  underline=True, color='#00a65d',\n",
    "                                  font='Marianne', size=40)\n",
    "    context = {\n",
    "                'mesure': rt_hyperlien,        \n",
    "                'title_table_nat' : \"Niveau National\", \n",
    "                'title_table_reg' : \"Niveau Régional\", \n",
    "                'title_table_dep' : \"Niveau Départemental\",\n",
    "                'lib_reg': reg_name, \n",
    "                'lib_dep': dep_name,\n",
    "                'col_labels' : col_labels, \n",
    "                # Les 3 lignes suivantes permettent de générer des tabeaux avec uniquement les 3 derniers mois.\n",
    "                # Prend en compte le cas ou il n'y a pas encore 3 mois de données\n",
    "                'tbl_contents_nat': [{'cols' : list(df_nat.iloc[-i-1])} for i in range(min(len(df_nat)-1, 3))],\n",
    "                'tbl_contents_reg': [{'cols' : list(df_reg.iloc[-i-1])} for i in range(min(len(df_reg)-1, 3))],\n",
    "                'tbl_contents_dep': [{'cols' : list(df_dep.iloc[-(i+1)])} for i in range(min(len(df_dep)-1, 3))],\n",
    "                'code_comment': \"{% for f in \" + encode_name(mesure) + \" %}{{ f.text }} {{ f.image }} {% endfor %}\",\n",
    "                }\n",
    "    doc.render(context)\n",
    "    name_file = \"reports_word/Generation_p2p/content_page_{}.docx\".format(mesure)\n",
    "    doc.save(name_file)\n",
    "    return name_file\n",
    "\n",
    "\n",
    "def creation_fiche(dep):\n",
    "    #departement: code departement 01:\n",
    "    #On a les variables volet2mesures, all_charts\n",
    "    reg = taxo_dep_df[taxo_dep_df['dep'] == dep].iloc[0]['reg']  # Code region\n",
    "    if reg in L_reg_no_output:\n",
    "        return False\n",
    "    num_volet, num_mesure = 1, 1\n",
    "    reg_name = taxo_reg_df[taxo_reg_df['reg'] == reg].iloc[0]['libelle']  # libelle\n",
    "    dep_name = taxo_dep_df[taxo_dep_df['dep'] == dep].iloc[0]['libelle']\n",
    "    name_fusion = creation_front_page(dep_name)\n",
    "    for volet in list(volet2mesures.keys()):  # 3 itérations, dep_name, reg_name\n",
    "        name_volet = creation_volet_page(volet, num_volet)\n",
    "        name_fusion = fusion_word(name_fusion, name_volet, dep_name)\n",
    "        liste_mesure = volet2mesures[volet]\n",
    "        num_volet += 1\n",
    "        for mesure in liste_mesure:\n",
    "            name_content = creation_content_page(all_charts_as_df, dep, reg, mesure, volet, dep_name, reg_name, num_mesure)\n",
    "            name_fusion = fusion_word(name_fusion, name_content, dep_name)\n",
    "            num_mesure += 1\n",
    "    return name_fusion\n",
    "            \n",
    "\n",
    "\n",
    "def create_all_dep():\n",
    "    list_all_dep = taxo_dep_df[~taxo_dep_df[\"dep\"].isin(L_dep_no_output)].dep\n",
    "    for dep in list_all_dep:\n",
    "        docx_path = creation_fiche(dep)\n",
    "        print(dep + ' ' + docx_path)\n",
    "        doc = Document(docx_path)\n",
    "\n",
    "        # Retirer le double espacement après les tableaux\n",
    "        for paragraph in doc.paragraphs:\n",
    "            # Retirer les lignes vides après les tableaux en fin de page : elles sont reconnues par la taille \n",
    "            # de la police <= 2 où ne possède pas de run.\n",
    "            if paragraph.text.__len__() == 0 and (any(run.font.size <= Pt(2) for run in paragraph.runs if run.font.size is not None) or \n",
    "                                                  (all(run.font.size is None for run in paragraph.runs))):\n",
    "                delete_paragraph(paragraph)\n",
    "        doc.save(docx_path)\n",
    "        \n",
    "        # Réduire la taille du paragraphe après le dernier tableau de chaque page\n",
    "        # Cela permet d'éviter de créer une nouvelle page quand le texte devient trop long\n",
    "        doc = Document(docx_path)\n",
    "        styles = doc.styles\n",
    "        style = styles.add_style('Custom_style2', WD_STYLE_TYPE.PARAGRAPH)\n",
    "        style.font.size = Pt(2)\n",
    "        for paragraph in doc.paragraphs:\n",
    "            if len(paragraph.text) == 1:\n",
    "                paragraph.style = doc.styles['Custom_style2']\n",
    "        doc.save(docx_path)\n",
    "\n",
    "        \n",
    "# Lance la génération dans le dossier reports_word\n",
    "create_all_dep()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_num_docx_created():\n",
    "    # Vérifier si on a bien toutes les fiches\n",
    "    num_test = len([fn for fn in os.listdir('reports_word') if \"Suivi\" in fn])\n",
    "    num_true = taxo_dep_df['dep'].shape[0]\n",
    "    # num_true-1 car on enlève le département Etranger \"00\"\n",
    "    assert num_test == num_true - 1, f\"{num_test} -- {num_true - 1}\"\n",
    "    \n",
    "check_num_docx_created()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}